---
title: "Lossy Compression for AI"
layout: presentation
location: Joint Laboratory for Extreme Scale Computing
date: 2020-09-01
description: >
  As time progresses, the volume of data surrounding machine learning and AI methods continues to grow from training, testing, and validation datasets to the models themselves. As the volume grows, there are increasing challenges in transporting and storing the data. Lossy compression techniques present the opportunity to drastically reduce the volume of data while maintaining or even improving upon the quality of the decisions made by AI. This talk presents a survey of novel research examining the effect of lossy compression on AI decision making in a variety of domains including medical data science and physics. We examine the effects of data ordering, error bounds, compression methodologies to make general recommendations from these and other areas regarding how to effectively leverage lossy compression in AI using the common LibPressio interface.
acknowledgments: This talk consists of research by Robert Underwood, Sheng Di, Jon C. Calhoun, and Franck Cappello
nolinks: true
...
