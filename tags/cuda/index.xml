<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Cuda on systems++</title><link>http://robertu94.github.io/tags/cuda.html</link><description>Recent content in Cuda on systems++</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 12 May 2018 08:00:14 -0500</lastBuildDate><atom:link href="http://robertu94.github.io/tags/cuda/index.xml" rel="self" type="application/rss+xml"/><item><title>Generic Cuda</title><link>http://robertu94.github.io/2018/05/12/generic-cuda.html</link><pubDate>Sat, 12 May 2018 08:00:14 -0500</pubDate><guid>http://robertu94.github.io/2018/05/12/generic-cuda.html</guid><description>GPU programming has the potential to make embarrassingly parallel tasks very quick. But what if you want to perform the same task on a variety of different types? In this post, I walk through a generic testing code that preforms a vector add on GPU and CPU to verify the correctness.
The Test Harness Our main function is pretty simple:
int main(int argc, char* argv[]) { check_type&amp;lt;int&amp;gt;(); check_type&amp;lt;long&amp;gt;(); check_type&amp;lt;double&amp;gt;(); check_type&amp;lt;float&amp;gt;(); return 0; } So how do we write check_type?</description></item></channel></rss>