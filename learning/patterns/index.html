<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#FFFFFF"><title>Learning to Learn: Software Patterns &#183; Systems++</title>
<meta name=title content="Learning to Learn: Software Patterns &#183; Systems++"><script type=text/javascript src=/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="></script><link type=text/css rel=stylesheet href=/css/main.bundle.min.f5d02fd21ba62de62cf162b932a2a9bf2ea60bb62b0c8226cfa8734afb546691.css integrity="sha256-9dAv0humLeYs8WK5MqKpvy6mC7YrDIImz6hzSvtUZpE="><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.d85fab7ccfc2112e9c50ae4adc7fa76fa179c95f40e02a11e18eb397acb6139e.js integrity="sha256-2F+rfM/CES6cUK5K3H+nb6F5yV9A4CoR4Y6zl6y2E54=" data-copy=Copy data-copied=Copied></script><meta name=description content="
      
        Foundation Parallel Operations #Fundamental to developing high-performance software is having an understanding of the basics of parallel architecture.
      
    "><link rel=canonical href=https://robertu94.github.io/learning/patterns/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://robertu94.github.io/learning/patterns/"><meta property="og:site_name" content="Systems++"><meta property="og:title" content="Learning to Learn: Software Patterns"><meta property="og:description" content="Foundation Parallel Operations #Fundamental to developing high-performance software is having an understanding of the basics of parallel architecture."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="learning"><meta property="article:published_time" content="2018-01-12T19:00:14-05:00"><meta property="article:modified_time" content="2018-01-12T19:00:14-05:00"><meta property="article:tag" content="Learning to Learn"><meta property="article:tag" content="Programming"><meta name=twitter:card content="summary"><meta name=twitter:title content="Learning to Learn: Software Patterns"><meta name=twitter:description content="Foundation Parallel Operations #Fundamental to developing high-performance software is having an understanding of the basics of parallel architecture."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","articleSection":"","name":"Learning to Learn: Software Patterns","headline":"Learning to Learn: Software Patterns","abstract":"\u003ch1 id=\u0022foundation-parallel-operations\u0022 class=\u0022relative group\u0022\u003eFoundation Parallel Operations \u003cspan class=\u0022absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\u0022\u003e\u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022 style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#foundation-parallel-operations\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\u003c\/span\u003e\u003c\/h1\u003e\u003cp\u003eFundamental to developing high-performance software is having an understanding of the basics of parallel architecture.\u003c\/p\u003e","inLanguage":"en","url":"https:\/\/robertu94.github.io\/learning\/patterns\/","author":{"@type":"Person","name":"Robert Underwood"},"copyrightYear":"2018","dateCreated":"2018-01-12T19:00:14-05:00","datePublished":"2018-01-12T19:00:14-05:00","dateModified":"2018-01-12T19:00:14-05:00","keywords":["Learning to Learn","Programming"],"mainEntityOfPage":"true","wordCount":"5883"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://robertu94.github.io/","name":"Systems","position":1},{"@type":"ListItem","item":"https://robertu94.github.io/learning/","name":"","position":2},{"@type":"ListItem","name":"Learning to Learn Software Patterns","position":3}]}</script><meta name=author content="Robert Underwood"><link href=https://github.com/robertu94 rel=me><link href=mailto:rr.underwood94@gmail.com rel=me><link href=/about rel=me><link href="https://scholar.google.com/citations?user=GbhfWUIAAAAJ&amp;hl=en" rel=me><link href=https://orcid.org/0000-0002-1464-729X rel=me><link href=https://www.youtube.com/@robertunderwood97 rel=me><link href=https://keybase.io/robertu94 rel=me><script defer type=text/javascript src=/js/mermaid.bundle.832624a553672a6ccda17159509c1ec6d0d691d57d975bab3ea0c67d4b5f45e838af68b83e8b06f78aa79c286b60388f54be6e274806fdbdc642a0019161d9e2.js integrity="sha512-gyYkpVNnKmzNoXFZUJwextDWkdV9l1urPqDGfUtfReg4r2i4PosG94qnnChrYDiPVL5uJ0gG/b3GQqABkWHZ4g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-9KQE44SX6K"></script><script>var dnt,doNotTrack=!1;if(!0&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-9KQE44SX6K")}</script></head><body class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden"><nav class="flex items-start justify-between sm:items-center"><div class="z-40 flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>Systems++</a></div><label id=menu-button for=menu-controller class="block sm:hidden"><input type=checkbox id=menu-controller class=hidden><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper class="invisible fixed inset-0 z-30 m-auto h-full w-full cursor-default overflow-auto bg-neutral-100/50 opacity-0 backdrop-blur-sm transition-opacity dark:bg-neutral-900/50"><ul class="mx-auto flex w-full max-w-7xl list-none flex-col overflow-visible px-6 py-6 text-end sm:px-14 sm:py-10 sm:pt-10 md:px-24 lg:px-32"><li class=mb-1><span class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class="group mb-1"><a href=/about/ title="About Me" onclick=close_menu()><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">About</span></a></li><li class="group mb-1"><a href=/posts/ title=Posts onclick=close_menu()><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Blog</span></a></li><li class="group mb-1"><a href=/guides/ title onclick=close_menu()><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Guides</span></a></li><li class="group mb-1"><a href=/learning/ title onclick=close_menu()><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Learning To Learn</span></a></li><li class="group mb-1"><button id=search-button-m0 title="Search (/)">
<span class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></span></button></li></ul></div></label><ul class="hidden list-none flex-row text-end sm:flex"><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0"><a href=/about/ title="About Me"><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">About</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0"><a href=/posts/ title=Posts><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Blog</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0"><a href=/guides/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Guides</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0"><a href=/learning/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Learning To Learn</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0"><button id=search-button-m1 title="Search (/)">
<span class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></span></button></li></ul></nav></header><div class="relative flex grow flex-col"><main id=main-content class=grow><article><header class=max-w-prose><h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Learning to Learn: Software Patterns</h1><div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2018-01-12 19:00:14 -0500 -0500">12 January 2018</time><span class="px-2 text-primary-500">&#183;</span><span>5883 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">28 mins</span></div></div></header><section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row"><div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8"><div class="toc pe-5 lg:sticky lg:top-10 print:hidden"><details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5"><summary class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#foundation-parallel-operations>Foundation Parallel Operations</a><ul><li><a href=#enumeration-and-grouping>Enumeration and Grouping</a></li><li><a href=#sendrecv>Send/Recv</a></li><li><a href=#collectives>Collectives</a></li><li><a href=#map>Map</a></li><li><a href=#scanreduce>Scan/Reduce</a></li></ul></li></ul></nav></div></details></div></div><div class="min-h-0 min-w-0 max-w-prose grow"><h1 id=foundation-parallel-operations class="relative group">Foundation Parallel Operations <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#foundation-parallel-operations aria-label=Anchor>#</a></span></h1><p>Fundamental to developing high-performance software is having an understanding of the basics of parallel architecture.</p><h2 id=enumeration-and-grouping class="relative group">Enumeration and Grouping <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#enumeration-and-grouping aria-label=Anchor>#</a></span></h2><h3 id=intent class="relative group">Intent <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#intent aria-label=Anchor>#</a></span></h3><p>Label each processing element in a group with a distinct label and describe new groups in a way that is consistent across nodes.</p><h3 id=motivation class="relative group">Motivation <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#motivation aria-label=Anchor>#</a></span></h3><p>Enumeration and grouping is foundational to other parallel primitives such as Send/Recv, which need these labels to identify sources and targets. It is often also used as a primitive in larger algorithms to statically partition work between a collection of processing elements. Lastly, programs might create multiple distinct enumerations for various subtasks to facilitate collectives on subsets of processes better, or create new groups dynamically to via collaboration with the scheduler to expand the quantity of resources for a task. This also applies to GPU device programming (e.g. threadId.x in CUDA).</p><h3 id=applicability class="relative group">Applicability <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#applicability aria-label=Anchor>#</a></span></h3><ul><li>As a fundamental primitive, it&rsquo;s applicable to almost all use cases</li><li>For systems with rapidly changing group members, other work partitioning schemes and addressing schemes that hide this aspect from the user may be more important</li></ul><h3 id=structure class="relative group">Structure <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#structure aria-label=Anchor>#</a></span></h3><div class=mermaid align=center>classDiagram
class User:::user
class ResourceManager:::optional {
+group(): Group
}
class Scheduler:::optional {
+allocate(r: Request): Lease
+deallocate(l: Lease)
}
class Element:::required
class Group:::required {
+id(Element: e): int
+size(): int
}
Group "1..n" <-- "1" Element: Belongs To
ResourceManager --> Group: Creates
ResourceManager <-- Scheduler: Provisions
Scheduler "1" --> "*" Element: Allocates/Deallocates
User "1" --> "1" Scheduler: Requests
classDef required fill:#f9f,stroke:#333,stroke-width:4px;
classDef optional fill:#bbf,stroke:#333,stroke-width:4px;
classDef user fill:#eea,stroke:#333,stroke-width:4px;</div><h3 id=participantselements class="relative group">Participants/Elements <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#participantselements aria-label=Anchor>#</a></span></h3><ul><li>Elements - an individual processing element</li><li>Groups – collections of processing elements</li><li>(optional) resource manager – a leader (see leader election) that decides identity within a group</li><li>(optional) scheduler – used to allocate/deallocate additional elements</li></ul><h3 id=collaboration-with-other-patterns class="relative group">Collaboration with other patterns <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#collaboration-with-other-patterns aria-label=Anchor>#</a></span></h3><ul><li>A fundamental concept used in most other operations</li><li>Dynamic group management often requires interaction with the scheduler and thus resource management patterns</li><li>Dynamic group management allows fault tolerance on collectives and thus resilience patterns</li></ul><h3 id=code-examples class="relative group">Code Examples <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#code-examples aria-label=Anchor>#</a></span></h3><p>MPI Comm examples using Sessions, which interact with the resource manager to create processes aligned with hardware resources</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cxx data-lang=cxx><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;mpi.h&gt;</span><span style=color:#75715e>  
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>  
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdlib.h&gt;</span><span style=color:#75715e>  
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;string&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(<span style=color:#66d9ef>int</span> argc, <span style=color:#66d9ef>char</span> <span style=color:#f92672>*</span>argv[]) {
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Initialize an MPI session  
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    MPI_Session session;  
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> err <span style=color:#f92672>=</span> MPI_Session_init(MPI_INFO_NULL, MPI_ERRORS_RETURN, <span style=color:#f92672>&amp;</span>session);  
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> (err <span style=color:#f92672>!=</span> MPI_SUCCESS) {  
</span></span><span style=display:flex><span>        fprintf(stderr, <span style=color:#e6db74>&#34;MPI_Session_init failedn&#34;</span>);  
</span></span><span style=display:flex><span>        MPI_Abort(MPI_COMM_WORLD, err);  
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>//query the runtime what processes sets exist (implementation defined)  
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> num_p_sets;  
</span></span><span style=display:flex><span>    MPI_Session_get_num_psets(session, MPI_INFO_NULL, <span style=color:#f92672>&amp;</span>num_p_sets);  
</span></span><span style=display:flex><span>    std<span style=color:#f92672>::</span>string pset_name;  
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> num_p_sets; <span style=color:#f92672>++</span>i) {  
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>int</span> psetlen <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;  
</span></span><span style=display:flex><span>        MPI_Session_get_nth_pset(session, MPI_INFO_NULL, i, <span style=color:#f92672>&amp;</span>psetlen, NULL);  
</span></span><span style=display:flex><span>        pset_name.resize(psetlen <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#39;0&#39;</span>);  
</span></span><span style=display:flex><span>        MPI_Session_get_nth_pset(session, MPI_INFO_NULL, i, <span style=color:#f92672>&amp;</span>psetlen, pset_name.data());
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e>//match the specified process set  
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>if</span> (pset_name <span style=color:#f92672>==</span> argv[<span style=color:#ae81ff>1</span>]) <span style=color:#66d9ef>break</span>;  
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>//groups on their own do not facilitate communication, they just enumerate processes  
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    MPI_Group world_group;  
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> (MPI_Group_from_session_pset(session, pset_name.c_str(), <span style=color:#f92672>&amp;</span>world_group) <span style=color:#f92672>!=</span> MPI_SUCCESS) {  
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>1</span>;  
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> grank, gsize;  
</span></span><span style=display:flex><span>    MPI_Group_rank(world_group, <span style=color:#f92672>&amp;</span>grank);  
</span></span><span style=display:flex><span>    MPI_Group_size(world_group, <span style=color:#f92672>&amp;</span>gsize);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    printf(<span style=color:#e6db74>&#34;Hello from grank %d out of %dn&#34;</span>, grank, gsize);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>//create a communicator to actually communicate between the processes  
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    MPI_Comm comm;  
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> (MPI_Comm_create_from_group(world_group, <span style=color:#e6db74>&#34;world_set&#34;</span>, MPI_INFO_NULL, MPI_ERRORS_RETURN, <span style=color:#f92672>&amp;</span>comm) <span style=color:#f92672>!=</span> MPI_SUCCESS) {  
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>1</span>;  
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> rank, size;  
</span></span><span style=display:flex><span>    MPI_Comm_rank(comm, <span style=color:#f92672>&amp;</span>rank);  
</span></span><span style=display:flex><span>    MPI_Comm_size(comm, <span style=color:#f92672>&amp;</span>size);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    printf(<span style=color:#e6db74>&#34;Hello from rank %d out of %dn&#34;</span>, rank, size);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Cleanup  
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    MPI_Comm_free(<span style=color:#f92672>&amp;</span>comm);  
</span></span><span style=display:flex><span>    MPI_Group_free(<span style=color:#f92672>&amp;</span>world_group);  
</span></span><span style=display:flex><span>    MPI_Session_finalize(<span style=color:#f92672>&amp;</span>session);  
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;  
</span></span><span style=display:flex><span>}  
</span></span></code></pre></div><p>MPI Comm example using COMM_WORLD</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cxx data-lang=cxx><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;mpi.h&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(<span style=color:#66d9ef>int</span> argc, <span style=color:#66d9ef>char</span><span style=color:#f92672>*</span> argv[]) {
</span></span><span style=display:flex><span>    MPI_Init(<span style=color:#f92672>&amp;</span>argc, <span style=color:#f92672>&amp;</span>argv);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> rank, size;  
</span></span><span style=display:flex><span>    MPI_Comm_rank(MPI_COMM_WORLD, <span style=color:#f92672>&amp;</span>rank);  
</span></span><span style=display:flex><span>    MPI_Comm_size(MPI_COMM_WORLD, <span style=color:#f92672>&amp;</span>size);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    printf(<span style=color:#e6db74>&#34;Hello from rank %d out of %dn&#34;</span>, rank, size);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    MPI_Finalize();
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>CUDA kernel launch examples</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;random&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;vector&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>vadd</span>(<span style=color:#66d9ef>float</span><span style=color:#f92672>*</span> a, <span style=color:#66d9ef>float</span><span style=color:#f92672>*</span> b, <span style=color:#66d9ef>float</span><span style=color:#f92672>*</span> c, size_t n) {
</span></span><span style=display:flex><span>    <span style=color:#75715e>//enumerates a block
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    i <span style=color:#f92672>=</span> threadIdx.x <span style=color:#f92672>+</span> blockIdx.x <span style=color:#f92672>*</span> blockDim.x;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>//because the number of tasks may not be evenly divisible by what is
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>//efficent on the hardware you almost always get a more threads than tasks
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span> (i <span style=color:#f92672>&lt;</span> n) {
</span></span><span style=display:flex><span>        c[i] <span style=color:#f92672>=</span> b[i] <span style=color:#f92672>+</span> a[i];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(){
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>constexpr</span> size_t dims <span style=color:#f92672>=</span> <span style=color:#ae81ff>1024</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>//performs
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    std<span style=color:#f92672>::</span>vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span> h_a(dims);
</span></span><span style=display:flex><span>    std<span style=color:#f92672>::</span>vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span> h_b(dims);
</span></span><span style=display:flex><span>    std<span style=color:#f92672>::</span>uniform_real_distribution<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span> dist;
</span></span><span style=display:flex><span>    std<span style=color:#f92672>::</span>mt19937 gen;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>auto</span> rng <span style=color:#f92672>=</span> []{ <span style=color:#66d9ef>return</span> dist(gen); };
</span></span><span style=display:flex><span>    std<span style=color:#f92672>::</span>generate(std<span style=color:#f92672>::</span>begin(h_a), std<span style=color:#f92672>::</span>end(h_a), rng);
</span></span><span style=display:flex><span>    std<span style=color:#f92672>::</span>generate(std<span style=color:#f92672>::</span>begin(h_b), std<span style=color:#f92672>::</span>end(h_b), rng);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>d_a,<span style=color:#f92672>*</span>d_b,<span style=color:#f92672>*</span>d_c;
</span></span><span style=display:flex><span>    cudaMalloc(<span style=color:#f92672>&amp;</span>d_a, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>float</span>)<span style=color:#f92672>*</span>dims);
</span></span><span style=display:flex><span>    cudaMalloc(<span style=color:#f92672>&amp;</span>d_b, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>float</span>)<span style=color:#f92672>*</span>dims);
</span></span><span style=display:flex><span>    cudaMalloc(<span style=color:#f92672>&amp;</span>d_c, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>float</span>)<span style=color:#f92672>*</span>dims);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaMemcpy(d_a, h_a.data(), dims<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>float</span>), cudaMemcpyHostToDevice);
</span></span><span style=display:flex><span>    cudaMemcpy(d_b, h_b.data(), dims<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>float</span>), cudaMemcpyHostToDevice);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    size_t threads_per_block <span style=color:#f92672>=</span> <span style=color:#ae81ff>256</span>;
</span></span><span style=display:flex><span>    size_t blocks_per_grid <span style=color:#f92672>=</span> (dims<span style=color:#f92672>+</span>threads_per_block<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>/</span>threads_per_block;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>//requests creation of block_per_grid*threads_per_block threads
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>//threads_per_block has a max limit based on hardware width
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#f92672>&lt;&lt;&lt;</span>blocks_per_grid, threads_per_block<span style=color:#f92672>&gt;&gt;&gt;</span>vadd(d_a, d_b, d_c, dims);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaMemcpy(h_c.data(), d_c, dims<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>float</span>), cudaMemcpyDeviceToHost);
</span></span><span style=display:flex><span>    cudaFree(d_a);
</span></span><span style=display:flex><span>    cudaFree(d_b);
</span></span><span style=display:flex><span>    cudaFree(d_c);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>// etcd</p><pre tabindex=0><code></code></pre><h3 id=concequences-pros-and-cons-of-use class="relative group">Concequences (pros and cons of use) <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#concequences-pros-and-cons-of-use aria-label=Anchor>#</a></span></h3><ul><li>Use of groups may simplify programming by allowing collective operations to be used as opposed to independent operations</li><li>The creation of strongly consistent groups is a syncronization point which inroduces overhead especially for extreemly large number of processing elements.</li></ul><h3 id=implementation-considerations class="relative group">Implementation considerations <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#implementation-considerations aria-label=Anchor>#</a></span></h3><ul><li>Static vs Dynamic number of processing elements – this addresses whether or not groups can be created or destroyed at runtime by introducing or removing processing elements. The creating groups proses an operational challenge if the number of nodes exceeds the current resource request because the overall system may not have sufficent resources to satisfy the request. In which case the scheduler accepts immediately, either refueses, or accepts with a delay. Refusing could result in the task having insufficent resources, delaying often causes waiting while resources are allocated. The case where the new request is fits within an existing allocation is much more operatoinally simple, but requires additional resources be allocated by scheduler but for some of the job might be unused.</li><li>Static vs Dynamic membership of groups – this addresses whether or not an existing groups membership can change. Allowing changes of group membership allows for more better handling of failures and more dynamic right-sizing of resource needs, but increases complexity to handle cases where a node is deallocated from or added to a group.</li><li>Strict consistency vs Weak consistency – can group members have an inconsistent view of group membership? Weak consistency can enable lower overhead (from less syncronization), more scalablity (from less syncronization) and greater fault tolerance (because groups can remain if one of its members die). Strong consistency of group membership is dramatically easier to reason about.</li></ul><h3 id=known-uses class="relative group">Known uses <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#known-uses aria-label=Anchor>#</a></span></h3><ul><li>MPI_Communicators are strongly consistent<ul><li>MPI_Comm_size, MPI_Comm_rank – get the number of processing elements in a group and the id of a specific processing element</li><li>MPI_Comm_split – allows creating subgroups from existing resources</li><li>MPI_Comm_spawn – allows creating new groups on additional resources</li><li>MPI_Comm_connect – allows connecting two groups</li></ul></li><li>etcd, zookeeper, mochi-ssg – implements weakly consistent dynamic group management</li><li>CUDA – strongly consistent, uses dynamic group creation, but not dynamic membership changes</li></ul><h2 id=sendrecv class="relative group">Send/Recv <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#sendrecv aria-label=Anchor>#</a></span></h2><h3 id=intent-1 class="relative group">Intent <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#intent-1 aria-label=Anchor>#</a></span></h3><p>Fundmental primiative describing point to point communication between two processing elements.</p><h3 id=motivation-1 class="relative group">Motivation <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#motivation-1 aria-label=Anchor>#</a></span></h3><p>Without some mechanism to communicate between physically distinct hardware, parallel and distributed software does not exist. It important to note this even applies withing a single node on systems featuring multiple Non Uniform Memory Access (NUMA) domains which violate traditional Von Neuman assumptions around system architecture by having some memory that is “lower latency” to computation on certain processing elements than others. It can seldonly be completely avoided.</p><h3 id=applicability-1 class="relative group">Applicability <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#applicability-1 aria-label=Anchor>#</a></span></h3><ul><li>As a fundemental primitive, it is applicable to almost all use cases</li><li>Some communication patterns can be more consisely expressed using higher level primatives which can then be then be specialized for the underlying hardware capabilties. In such cases, higher level collective operations can be used.</li><li>Some uses cases (e.g. consistent and partition tolerant systems like traditional relational database managment systems like PostgresQL, some aspects of filesystems) require frequent syncronization to maintain consistency. In such systems, avoiding distributing the workload requires fewer expensive syncronizations that occur over the network and may improve performance.</li></ul><h3 id=structure-1 class="relative group">Structure <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#structure-1 aria-label=Anchor>#</a></span></h3><h3 id=participantselements-1 class="relative group">Participants/Elements <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#participantselements-1 aria-label=Anchor>#</a></span></h3><ul><li>Message – what is being sent</li><li>Sender – who is communicating information</li><li>Reciever – who is obtaining information</li><li>Switch(es)/Interconnect – intermediate network devices/nodes that transpartently conveys a message</li></ul><h3 id=collaboration-with-other-patterns-1 class="relative group">Collaboration with other patterns <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#collaboration-with-other-patterns-1 aria-label=Anchor>#</a></span></h3><ul><li>Scatter/Gather/Broadcast – depending on hardware, these higher level collectives are implemented in terms of a point-to-point communication method.</li><li>Hardware specialization – these routines are so primiative that often one or more aspect of them are implemented in dedicated hardware</li><li>Pooling – often underlying resources use for sending and recieving messages are pooled</li><li>Syncronization and Resilance patterns – use these as a primitive</li></ul><h3 id=code-examples-1 class="relative group">Code Example(s) <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#code-examples-1 aria-label=Anchor>#</a></span></h3><p>// example from an RPC based system</p><p>// example from MPI</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cxx data-lang=cxx></code></pre></div><p>// example from MPI One-sided</p><p>// example from MPI partitioned send</p><p>// example from a GASNet based approach</p><h3 id=concequences class="relative group">Concequences <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#concequences aria-label=Anchor>#</a></span></h3><ul><li>Communication incurs overhead which is often orders of magnitude slower than simple computations.</li><li>Communication enables greater access to resources via horizontal scaling (more nodes) which is often cheaper than vertical scaling (more powerful nodes) past a certain scale due to the difficulty of implicity maintaining coherence on progressively larger systems.</li><li>Communication introduces complexity of managing distributed state to the application</li><li>Communication enables fault recovery and resilance by reducing the probability of a single point of failiure from a single node failure.</li></ul><h3 id=implementation-considerations-1 class="relative group">Implementation considerations <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#implementation-considerations-1 aria-label=Anchor>#</a></span></h3><ul><li>Implicit (Global Address Space) vs Explicit (e.g. Message Passing). There are two fundemental models of communication – explicit models where the programmer specifically describes which processes send and which recieve – this describes UNIX sockets as well as HPC oriented solutions such as MPI. There is however an alternative with global addressing systems which instead make communication implict much like the communication between threads. At scale, there tends to be a tradeoff between performance (explicit) and productivity (implicit), but depending on the usage pattern, this performance overhead can be either minimal or catestrophic.</li><li>Message Sizes – The performance of small messages are dominated by the latency to send any data at all. Large messages are dominated by the bandwidth of the system. Often there is a tradeoff between latency and throughput. Frequenly a small amount of throughput can be sacrificed for much lower latency. Frequenly, these choices are made by your networking library, but may be tunable for a specific code.</li><li>Addressing – How do you identify a specific sender or reciever pair? Systems such as MPI use an integer value `rank` to identify a specific processing element within a communicator (group of processing elements). For recieving operations, MPI allows recieving from any process in a group which enables implementing constructs like work queues. MPI further specifies this with TAGs which allow multiple distinct messages to be sent concurrently – e.g. to impement a cancelation channel or to indicate an exception channel.</li><li>Routing – how is the route between nodes determined. Often this is the responsability of the networking library or hardware. Some network topologies (e.g. fat-trees, toruses) have specialized routing algorithms that minimize contention or ensure low latency. Other topologies feature slow links (e.g. wide area networks) that may need to be deprioritized. Lastly, some networking libraries and hardware allow for “multi-path” communication which enables higher throughput at the cost of additional adminstrative and implementation complexity.</li><li>Asyncronous vs Syncronous – are the routines to initate sends blocking with respect to the caller, or not? Non-blocking routines enable the overlapping of computation with communication, but at the cost of increased complexity. Modern hardware is natively asyncronous with respect to the CPU.</li><li>Zero Copy – are copies require to send messages? In UNIX sockets, the user provided buffer supplied to send() is copied to user space to kernel space before the routine returns. Then the kernel copies from the kernel based buffer to the network interface where the message is transmitted to the recieving node which then copies the data from its network interface to a kernel buffer, before it is finally copied to the user memory. In zero copy networking, the user writes directly to the sends network interface’s buffer and the recieving node’s network interface writes directly to user memory bypassing copies to the kernel. This potentially has security trade-offs if implemented poorly, but can dramtically improve send/recv latency.</li><li>OS Bypass – In UNIX sockets, a system call write()/read() is required to initiate a read or write on the network which incurs overhad from context switching as well as potential overhead from context switching to other tasks which are prefered along system call boundries.</li><li>“Queueing” and SENDRECV – even when using zero copy transfers, it is possible that the network interface may not have suffcent capacity to accomidate all read/write requests and a request will need to queued. To prevent deadlocks from queuing in large pair-wise exchanges, “buffered sends” or “asyncronous sends and recieves” which pre-allocate the network interface memory or alternatively combined “sendrecv” can be used which atomically swap buffers can be used to avoid deadlock. Queuing can be mangaed by the network interface or or coordinated by the switchs/routers on the network (in the case of infiniband).</li><li>Partitioned Operations and Device Initiated Sends – currently some devices (e.g. GPUs) have limited ability to initate network operations on their own, and require another device (e.g. the CPU or the network interface) to initate the request. Some fabrics and devices implment so-called partiioned sends which divide the declaration that a send should occur from the declaration that memory is ready to send, and from the actual send of the data. In such cases, the network interface enques a task to initate the sends/recieves on the behalf of the device using low level routines that allow the device to wait for a condition (e.g cuStreamWaitValue32 which issues a callback when a particular memory address is set to a particular value). This is frequently combined with atomic additions or bitwise operations to indicate that an operation is ready. At time of writing this requires close collaboration between the network and device (e.g. HPE Slingshot 11 and Nvidia CUDA). A special case of this exists for sends (writes) and recvs (reads) from the filesystem under branding like GPUDirect Storage.</li><li>Reliability – does the protocol (e.g. tcp/udp, infiniband RC/UC) ensure that messages are actually delievered. Reliable messages are easier to reason about, but are less robust to heavy contention or packet loss scenarios where latency can spike as messages are retransmitted to ensure delivery. Unreliable messages in contrast have no delivery garuntees, but if the application tolerates some information loss (e.g. video transmission, gossip messages), unreliable messages can be used to greatly reduce latency.</li><li>Error Handling – how are errors identified and reported to the user? Some errors can be definitivley return (e.g. ENOPERM for disallowed operations), but others can be harder to detect especially in the context of node failures which can be difficult to distinguish from heavy contention or insufficent progress. See heart beat and gossip protocols for more information.</li><li>One Sided vs Two Sided – are both sides of the communication involved with the communication or is just one? Two sided operations are classic in explicit message passing systems. One sided operations utilize a hardware feature known as remote direct memory access (RDMA) to allow remote hosts to issues commands to read or write to user space memory on a remote host and are present in both global address based systems as well as modern explicit message passing libraries. In the case of two sided operations, the sender and reciever are syncroized when the message is communicated, but one-sided operations, some other mechanism is used to explicity syncronize calls to lower overhead (e.g. communication epochs).</li><li>Progress – how does the system decide when to actually perform operations. Some system require explicit progress to give control about when operations are performed to provide lower latency. Others implicity handle progress either specific calls that advance progress as collateral to other operations, or with a dedicated progress thread which can be simplier to use.</li><li>Atomisity – what operations can be performed on remote memory? At its simplist, read/writes are allowed, but more modern systems allow certain atomic operations such as arithmatic, bitwise, and certian other operations to be preformed in such a way that either the entire operation is performed or none of the operation is performed allowing lower overhead and not requring return messages. Hardware frequently limits this to a single 64 bit instruction having atomic operations. If an array of such values are “atomically” operated on, each value is independently treated as atomic but the ordering of operations to each value may be arbitarily interleaved.</li><li>Security – in HPC systems, security of communication is often handled at the network level and communication initation stage rather than at the node level while non-HPC system often implement security at the node level assuming the network is untrusted. This allows less overhead enforcing access controls, but requires a trusted adminstrative domain.</li></ul><h3 id=known-uses-1 class="relative group">Known uses <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#known-uses-1 aria-label=Anchor>#</a></span></h3><ul><li>Lower Level<ul><li>TCP/UDP/ROCE over IP</li><li>IO_URing</li><li>Infiniband</li><li>Machine Specific HPC Fabrics Slingshot/ToFuD</li></ul></li><li>Higher Level<ul><li>MPI Implementations of Send/Recv, MPI_Win one sided functions</li><li>RPC systems (e.g. Mochi, GRPC)</li><li>GASNet based Languages (e.g. Chapel, upc++)</li><li>Device &lt;-> Host in GPU Programing (e.g. OpenMP Target, CUDA, SYCL, etc…)</li></ul></li></ul><h2 id=collectives class="relative group">Collectives <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#collectives aria-label=Anchor>#</a></span></h2><h3 id=intent-2 class="relative group">Intent <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#intent-2 aria-label=Anchor>#</a></span></h3><p>A collective operations that send data from one node to collection of other nodes either in whole (broadcast) or in part (scatter) of others or visa versa to send from many nodes to one node (gather) or all nodes (allgather), or from all nodes to all other nodes (all to all).</p><h3 id=motivation-2 class="relative group">Motivation <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#motivation-2 aria-label=Anchor>#</a></span></h3><p>These are foundational communication patterns for group of nodes. This might be used to spread work out to a group of nodes, inform them of a request, wait for them (or some subset of them) to complete a request.</p><h3 id=applicability-2 class="relative group">Applicability <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#applicability-2 aria-label=Anchor>#</a></span></h3><ul><li>As a fundemental primitive, it is applicable to almost all use cases</li><li>Collectives are often “implicit” in global address space schemes so may not be explicity invoked by the user making them less relevent in this context.</li><li>The larger the group of processes collectively performing some task, the greater the overhead can be from a straggler who takes a disproportionately long time to complete the collective operation.</li></ul><h3 id=structure-2 class="relative group">Structure <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#structure-2 aria-label=Anchor>#</a></span></h3><h3 id=participantselements-2 class="relative group">Participants/Elements <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#participantselements-2 aria-label=Anchor>#</a></span></h3><ul><li>(optional) a root process [for broadcast, gather, scatter]</li><li>A group of processing elements</li></ul><h3 id=collaboration-with-other-patterns-2 class="relative group">Collaboration with other patterns <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#collaboration-with-other-patterns-2 aria-label=Anchor>#</a></span></h3><ul><li>As a fundemental primative, this patterns is used to build many large patterns</li></ul><h3 id=code-example class="relative group">Code Example <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#code-example aria-label=Anchor>#</a></span></h3><h3 id=concequences-1 class="relative group">Concequences <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#concequences-1 aria-label=Anchor>#</a></span></h3><ul><li>Collective simplify code and allow performance portability accross diverse architectures.</li><li>Collectives can become a point of failure in large jobs when one or more nodes fail during a collective</li></ul><h3 id=implementation-considerations-2 class="relative group">Implementation considerations <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#implementation-considerations-2 aria-label=Anchor>#</a></span></h3><ul><li>Syncronous vs Asyncronous – asyncronous collectives allow computation or other communication to occur during a collective operation, but increase the complexity of the underlying implementation</li><li>Non-contigious collectives – collectives may support sending different quantties of information during a collective (e.g. gatherv/scatterv)</li><li>Cancelation – can an operation be canceled after it has been started, if so is the cancelation premptive or collaborative? Allowing cancelation makes it easier to implement patterns such as “racing” queries where you want the first and then not wasting resources on the remaining operation</li><li>Toleration of stagglers/failures – does the collective require all nodes to complete the operation, or mearly some predetermined fraction of them?</li><li>Topology awareness – especially in the context of wide area network such as on the Eagle supercomputer which spans multiple datacenters and some links between nodes are dramatically slower than others. In such as system, these algorithms should be specialized to avoid sending more communication over the slow link than is strictly nessisary either communication batching strategies or ordering of pairwise steps in the collective.</li><li>Choice of algorithms<ul><li>Ring – process i sends to process i+1%n<ul><li>Torrus – a special case of ring algorithms where the ring is aligned to the torus network topology</li></ul></li><li>Butterfly– has a consistent more consistent runtime per process in the collective</li><li>Bionomial Tree – minimizes volumes of communication and maximizes throughput by communicating in k-nary tree</li><li>Linear – offers lower latency in some cases (e.g. small numbers of processes sending small messages)</li></ul></li></ul><h3 id=known-uses-2 class="relative group">Known uses <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#known-uses-2 aria-label=Anchor>#</a></span></h3><ul><li>MPI Collectives</li><li>NCCL (network)/CUB(device) collectives for CUDA</li></ul><h2 id=map class="relative group">Map <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#map aria-label=Anchor>#</a></span></h2><h3 id=intent-3 class="relative group">Intent <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#intent-3 aria-label=Anchor>#</a></span></h3><p>Applies the “same” function to a collection of tasks in parallel</p><h3 id=motivation-3 class="relative group">Motivation <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#motivation-3 aria-label=Anchor>#</a></span></h3><p>This is a foundational programming pattern. It can be used in parallel or serial cases whenever &ldquo;the same&rdquo; independent operation needs to be performed on a collection of elements.</p><h3 id=applicability-3 class="relative group">Applicability <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#applicability-3 aria-label=Anchor>#</a></span></h3><ul><li>As a fundamental primitive, it is applicable to many use cases</li><li>This pattern is still applicable for use cases where different operations (including no-ops) need to be performed on non-overlapping subsets of elements provided that the decision of which operation should be performed can be determined only by considering each element individually.</li><li>Not appropriate for cases where tasks need to synchronize/communicate with each other, instead consider reductions or scans</li></ul><h3 id=structure-3 class="relative group">Structure <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#structure-3 aria-label=Anchor>#</a></span></h3><h3 id=participantselements-3 class="relative group">Participants/Elements <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#participantselements-3 aria-label=Anchor>#</a></span></h3><ul><li>Workers – who performs the tasks</li><li>Tasks – the actual work to be performed</li><li>(optional) Scheduler – decides which tasks process each work element</li></ul><h3 id=collaboration-with-other-patterns-3 class="relative group">Collaboration with other patterns <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#collaboration-with-other-patterns-3 aria-label=Anchor>#</a></span></h3><ul><li>Load balancing – load balancing patterns can be used to deal with imbalanced workloads which require inconsistent quantities of resources per task</li><li>Resource Management – how tasks are assigned to resources can dramatically effect performance</li><li>Hardware specialization – common and foundational operations are often implemented in hardware (e.g. vector addition, matrix matrix multiply for small matrices) in a paradigm referred to as Single Instruction Multiple Data (SIMD). GPUs implement Single Instruction Multiple Threads (SIMT) which allows for an additional level of hierarchy.</li></ul><ul><li>Fault Tolerance - how errors and cancellation are handled has implications for fault tolerance of parallel maps especially checkpointing, bulkheads, replicas and algorithm based fault tolerance.</li></ul><h3 id=code-example-1 class="relative group">Code Example <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#code-example-1 aria-label=Anchor>#</a></span></h3><h3 id=consequences class="relative group">Consequences <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#consequences aria-label=Anchor>#</a></span></h3><ul><li>Tasks can be distributed over processing elements in parallel allowing for less wallclock execution time.</li><li>Starting/tearing down parallel resources has some overhead, or may introduce less regular data access patterns resulting in less efficent data access than the serial case.</li></ul><h3 id=implementation-considerations-3 class="relative group">Implementation considerations <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#implementation-considerations-3 aria-label=Anchor>#</a></span></h3><ul><li>Serial vs parallel &ndash; are the tasks performed in serial or in parallel. Performing tasks in serial may be optimal when the overhead for creating the workers or scheduling the tasks exceeds the benefits from parallel execution.</li><li>Task heterogenitity vs homogenity &ndash; heterogeneous tasks often feature greater load imbalance than homogeneous tasks and may be harder to schedule on certain kinds of hardware platforms. For example on GPUs, there is both a limit on the number of heterogenous tasks that can execute concurrently (which can be lower than on CPUs), but even for homogenous workflows also when there is divergence in the workflow (e.g. some tasks take different branches of an &ldquo;if&rdquo; statement), GPUs may pause execution on for threads while other threads in the same team take a different branch resulting in dramatically increase execution time.</li><li>Static vs dynamic task assignment &ndash; once a task is assigned to a worker, can the task be re-assigned to another worker? Cluster wide HPC schedulers (e.g. Slurm, PBS) tend to perform static task assignment which is much easier to implement. Node local, tasking runtime, and cloud oriented schedulers (e.g. Linux, OpenMP, Kubernetes) may perform dynamic task assignment to better balance load, to facilitate system maintenance, or to perform efficient packing of jobs. Dynamic scheduling often requires careful attention to task migration, but is easier in the case of &ldquo;Map&rdquo; tasks which are independent. See work stealing for additional discussion.</li></ul><ul><li>Collective vs Non-Collective &ndash; do all workers obtain the results of the other workers after the map is completed (i.e. Collective) or not (i.e. non-Collective)? A non-collective implementation can be made to be collective by adding a collective operation (e.g. gather or all-gather) after the map; collective implementations can be easier to reason about. See collectives.</li><li>Returning <code>void</code> &ndash; sometimes the user does not care about the return value of the function only that the side effects of the function occur eventually (e.g. Providing a progress notification to the user, or reporting some metrics to metrics collection endpoint). These are sometimes called &ldquo;fire-and-forget&rdquo; functions or &ldquo;detached&rdquo; functions. In practice, I find the true use cases for this to be rare; you almost always want to know if something failed unexpectedly and be able to handle that condition or to ensure that something eventually completes (e.g. asynchronous checkpointing). Instead prefer queuing style systems where error conditions and progress can be handled in a structured way.</li><li>Preserving the ordering to tasks &ndash; if tasks are provided in the order from 1..N, are they returned in the same order or some other order. Returning tasks in a different order (e.g. In the order of completion) may reduce synchronization between tasks, but introduces synchronization where the elements are returned as tasks compete to be the next value to return.</li><li>lazy vs eager &ndash; are the tasks launched as soon as the function and returned synchronously (e.g. <code>Vector&lt;T></code>) is called or are they called later either all at once (e.g. <code>Future&lt;Vector&lt;T>></code>) or batch by batch (e.g. <code>Generator&lt;T></code> or <code>Generator&lt;Vector&lt;T>></code>). Lazy execution can be more resource efficient if not all tasks are required or can reduce the operating memory overhead by not materializing the entire structure in memory.</li></ul><ul><li>Static or dynamic queue contents &ndash; are all tasks known at the beginning of the execution of the first task, or are tasks added to the queue as the workflow progresses? Static queue contents may allow for more detailed and optimal scheduling decisions than in the dynamic case. If tasks are added to the queue, how are they scheduled relative to existing tasks? See resource management for additional discussion.</li><li>Cancellation &ndash; At which points can tasks be canceled? Popular choices include never unless the program is killed (e.g. CUDA), prior to task execution, at dedicated points during task execution (e.g. Green threads, pthread_cancel with deferred cancellation, see cooperative scheduling), or at any point (e.g. Linux threads, most HPC schedulers see task preemption). Allowing cancellation may requires additional synchronization or overhead compared to not allowing cancelation, but allows tasks that are no longer needed to be discarded.</li><li>Error Handling &ndash; what happens if an error occurs during the execution of a task? Does the entire program attempt to terminate (e.g. <code>MPI_ERRORS_FATAL</code>), does the task complete with an exception, does the task complete and the user is required to implement error handling? Like cancellation, this allows tasks to end earlier than expected, but unlike cancellation may effect fault tolerance</li><li>scheduling &ndash; discussed in more detail for scans and reduces which introduces task dependencies. Even in the case of maps, scheduling decisions can be made based on expected/allocated execution time, resource utilization and availability (e.g. requires a GPU but none is currently available), status (e.g. waiting for a file read), fairness (e.g. how to ensure the long tasks continue to make forward progress), priority, and in the case of real-time systems deadlines.</li></ul><h3 id=known-uses-3 class="relative group">Known uses <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#known-uses-3 aria-label=Anchor>#</a></span></h3><ul><li>the <em>Map</em> in <em>MapReduce</em> in Hadoop</li><li><code>#pragma omp parallel for</code> in OpenMP</li><li><code>Kokkos::parallel_for</code> in Kokkos</li><li>Job Arrays in OpenPBS/PBSPro/Slurm</li><li>Kubernetes Jobs with multiple completions</li></ul><h2 id=scanreduce class="relative group">Scan/Reduce <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#scanreduce aria-label=Anchor>#</a></span></h2><h3 id=intent-4 class="relative group">Intent <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#intent-4 aria-label=Anchor>#</a></span></h3><p>This pattern combines multiple elements of a data structure into a single cumulative result. The result can represent a single element (a reduction), or a collection of elements (a scan).</p><h3 id=motivation-4 class="relative group">Motivation <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#motivation-4 aria-label=Anchor>#</a></span></h3><p>Reductions and scans are foundational parallel programming patterns. They can be used in parallel and serial use cases where multiple element of a data structure need to be combined to produce a result.</p><h3 id=applicability-4 class="relative group">Applicability <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#applicability-4 aria-label=Anchor>#</a></span></h3><ul><li>As a fundamental primitive, it is applicable to almost all use cases where you need to combine the values of multiple elements of a data structure such as <code>filter</code> operations and <code>aggregations</code> (e.g. count, mean, etc&mldr;)</li><li>While it is possible to implement <code>map</code> using a scan, this will likely introduce undue synchronization overhead.</li></ul><h3 id=structure-4 class="relative group">Structure <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#structure-4 aria-label=Anchor>#</a></span></h3><h3 id=participantselements-4 class="relative group">Participants/Elements <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#participantselements-4 aria-label=Anchor>#</a></span></h3><ul><li>tasks &ndash; what work needs to be performed<ul><li>&ldquo;the zero/identity element&rdquo; &ndash; what is the initial state of the reduction, or alternatively how is the inital state created?</li><li>the binary operation &ndash; how are elements of the data structure combined? Is the operation associative, or effectful?</li></ul></li><li>workers &ndash; where the work of the reduction preformed</li><li>scheduler &ndash; how tasks are mapped to workers</li></ul><h3 id=collaboration-with-other-patterns-4 class="relative group">Collaboration with other patterns <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#collaboration-with-other-patterns-4 aria-label=Anchor>#</a></span></h3><p>Many of the same collaborations as Map. This list focuses on distinctive of Reduces/Scans.</p><ul><li>Operator Fusion and Reordering &ndash; the ordering of reductions compared to other operations can have substantial effects on the amount of work to be performed</li><li>Load balancing – reduces and scans are inherently less load balanced than map (i.e. the root of the reduction has more work to do than the leaves) so is a more important consideration.</li><li>Hardware specialization – common and foundational operations are often implemented in hardware (e.g. Vector dot product) in a paradigm referred to as Single Instruction Multiple Data (SIMD). GPUs implement hierarchical primitives (e.g. Shuffles, warp/group primitives) that can also accelerate these functions.</li><li>Synchronization patterns &ndash; unlike map, synchronization is inherent to reductions/scans so careful attention to these patterns is critical for performance and correctness.</li></ul><ul><li>Fault Tolerance &ndash; Unlike map, there are more meaningful intermediate states that can potentially be checkpointed, and more complexity in recovering from failures because the loss of a node necessitates additional communication with the other nodes that would otherwise need to cooperate in a reduction/scan.</li></ul><h3 id=code-examples-2 class="relative group">Code Examples <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#code-examples-2 aria-label=Anchor>#</a></span></h3><h3 id=consequences-of-using-pattern class="relative group">Consequences of using pattern <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#consequences-of-using-pattern aria-label=Anchor>#</a></span></h3><ul><li>parallel reductions can require less wallclock time by distributing the work to be performed over multiple processing elements.</li><li>more-so than map, reductions/scans require synchronizations that introduce overhead when conducted in parallel.</li></ul><h3 id=implementation-considerations-4 class="relative group">Implementation considerations <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#implementation-considerations-4 aria-label=Anchor>#</a></span></h3><ul><li>What kind of iterator model exists for the collection?<ul><li>For random access and continuious iterators parallelism is possible because multiple processors can &ldquo;jump&rdquo; to a portion of the collection for processing.</li><li>For input, output, forward, and bidirectional iterators limited parallelism is possible without first converting to a random or continuous iterator because the inherently serial nature of advancing iterators one by one prohibits parallelism.</li></ul></li><li>Are you producing a single result or a collection of results?<ul><li>scans (<code>scanl operation init collection :: Foldable f => (b -> a -> b) -> b -> f a -> f b</code> ) produce a collection of elements instead of a single element for example a prefix sum, a maximum value in each subtree, or a shortest path from one node to any node in a graph.</li><li>reductions (<code>foldl operation init collection :: Foldable f => (b -> a -> b) -> b -> f a -> b</code>) produce a single element such as a maximum, the final state of a state machine over a series of events, the depth of a tree, or the size of the largest connected component.</li><li>There are also variants of these operations such as &ldquo;Reduce by Key&rdquo; which uses a fused scan with a reduce to process a group of elements with the same key together.</li><li>There are other variants of reductions that take additional arguments to the reduction function (e.g. <code>paramorphisms</code> that pass the original data structure in addition to the reduction state, <code>histomorphisms</code> which can look at multiple preceding states) For more information refer to the paper <a href=https://yangzhixuan.github.io/pdf/fantastic-morphisms.pdf target=_blank rel=noreferrer>&ldquo;Fantastic Morphisms and Where to Find Them A Guide to Recursion Schemes&rdquo;</a>.</li></ul></li><li>What are the properties of the binary operation?<ul><li>magmas vs semi-groups and associativity. A magma is just a binary operation that peserves type. A semi-group godes further and requires that the operation be associative. Associativity is a key property in that it allows for operations to be grouped in an arbitary order which enables parallelism by allowing operations to be scattered to multiple parallel processing elements and performed in an arbitary order. Sometimes, it is possible to conduct these operations as if they are a true semi-group, but are not. For example floating point operations are not truely associative, but are approximately associative. By relaxing the constraint and allowing associtaivity, the computation can be performed faster, but at the cost of some accuracy. Further more a semi-group can be an Abelian semi-group further allowing communativity &ndash; or reordering of operations. This enables a further set of performance improvements by allowing more arbitary work stealing which is useful in the case of load imbalanced problems.</li><li>semi-groups vs monoids and the &ldquo;zero&rdquo;/&ldquo;identity&rdquo; element. A monoid is just a semi-group that has a &ldquo;zero element&rdquo; also known as an &ldquo;identity element&rdquo;. The identity element combined using the binary operation with any other element produces the other element unchanged. For addtion, this is <code>0</code>; for multication this is <code>1</code>. Monoids offer an advantage over semigroups for parallelism because multiple elements can be &ldquo;lifted&rdquo; into the monoid using the identity element allowing for multiple starting positions instead of a single element. In contrast, for semi-groups, the user needs to provide an explicit base case of the reduction or scan.</li><li>monoids vs monads and effectful reductions. Monads are &ldquo;programmable semi-colons&rdquo; &ndash; they describe how to take the value in a &ldquo;wrapped&rdquo; value and return a new &ldquo;wrapped&rdquo; value &ndash; for example optionals and futures are monads. There are more abstact notions of monads such as <code>IO</code> in haskell that model side effects of calling functions (e.g. printing a value). If the order of the effects &ldquo;matters&rdquo; for the correctness of your program, this will limit parallelism. Just as you can sometimes &ldquo;cheat&rdquo; and ignore the ordering imposed by magmas you can do the same for monads (e.g. if two prints are out of order, that can be confusing for the debugging/monitoring of a program, but likely not impactful for correctness).</li></ul></li><li>The optimal implementation of a scan/reduce is effected by the programming model<ul><li>tree-based methods, 2 pass reduction. This pattern maps nicely onto many hardware types and is the principle way to implement distributed reductions. In this pattern, each iteration elements are paired up and passed to the binary function, and then the process is repeated taking the outputs of the pairs are passed to the as the inputs to the next iteration until only a single element remains. Some optimizations may implement this as a multi-level reduction the width of the nodes changes depending on their depth in the tree. To implement a scan using this design, a &ldquo;upward&rdquo; pass that computes the reduction of each subtree is computed, and then a &ldquo;downward&rdquo; pass computes the actual prefix values.</li><li>decoupled lookback &ndash; On CUDA and GPUs, scans can be efficiently implemented by leveraging the aspect of the hardware that threads are scheduled in a montonistically increasing manner. This means that the $i^{th}$ thread knows that at least threads $i-1$ have begun to execute (even if they haven&rsquo;t finished). Decoupled lookback combines this with hardware atomic operations to mark reductions as pending, prefix available , or aggregate available. In the case that fewer than $2^62$ elements are processed, the atomic store of the status can be stored with the aggregate into a single 64 bit integer register atomically.</li><li>For NPU and TPUs which feature hardware instructions for matrix-vector multiplication scans and reductions for certain datatypes can be implemented by multiplication by a specially designed matrix. For a scan, this is the upper triagular matrix of ones. For a reduction, it is the matrix where the matrix with the top row contains only ones.</li></ul></li><li>error handling and cancellation &ndash; unlike maps, reductions and scans have more complex error handling because the operations that fail may be intermediate results from the scan or reduction instead of from the raw elements. In this case, it may be desirable for a reduction to accumulate the errors either in an aabitary order (see magmas vs semigroups) or in the order of the original elements. This also has implications for recovering from failures as resuming from a failure in the middle of a reduction requires additional effort and careful syncroinzation during recovery. See the discussion on checkpointing of directed acyclic graphs for additional discussion.</li></ul><h3 id=known-uses-4 class="relative group">Known Uses <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#known-uses-4 aria-label=Anchor>#</a></span></h3><ul><li>MPI features Scan and Reduce collectives</li><li>OpenMP features Reduce and now Scan intents for loops.</li><li>Cuda&rsquo;s CUB (now part of NCCL) impement device (and collective) reductions respectively</li><li>In MapReduce/Hadoop, the Reducer implements a reduce by key.</li><li>Functional programming languages such as Haskell have the most robust notions of reductions (called fold) and scans.</li></ul></div></section><footer class="max-w-prose pt-8 print:hidden"><div class=flex><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Robert Underwood</div><div class="text-sm text-neutral-700 dark:text-neutral-400">Robert is an Assistant Computer Scientist in the Mathematics and Computer Science Division at Argonne National Laboratory focusing on data and I/O for large-scale scientific applications including AI for Science using techniques of lossy compression, and data management. He currently co-leads the AuroraGPT Data Team with Ian Foster. In addition to AI, Robert’s library LibPressio, allows users to experiment and adopt advanced compressors quickly, has over 200 average unique monthly downloads, is used in over 17 institutions worldwide, and he is also a contributor to the R&amp;D100 winning SZ family of compressors and other compression libraries. He regularly mentors students and is the early career ambassador for Argonne to the Joint Laboratory for Extreme Scale Computing.</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://github.com/robertu94 target=_blank aria-label=Github rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=mailto:rr.underwood94@gmail.com target=_blank aria-label=Email rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg>
</span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=/about target=_blank aria-label=Link rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg>
</span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href="https://scholar.google.com/citations?user=GbhfWUIAAAAJ&amp;hl=en" target=_blank aria-label=Google-Scholar rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg height="16" width="16" viewBox="0 0 512 512"><path fill="currentcolor" d="M390.9 298.5s0 .1.1.1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64h0c1.7-3.6 3.6-7.2 5.6-10.7 4.4-7.6 9.4-14.7 15-21.3 27.4-32.6 68.5-53.3 114.4-53.3 33.6.0 64.6 11.1 89.6 29.9 9.1 6.9 17.4 14.7 24.8 23.5 5.6 6.6 10.6 13.8 15 21.3 2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0 512 202.7l-94.7 77.1z"/></svg></span></a>
<a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://orcid.org/0000-0002-1464-729X target=_blank aria-label=Orcid rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M294.75 188.19h-45.92V342h47.47c67.62.0 83.12-51.34 83.12-76.91.0-41.64-26.54-76.9-84.67-76.9zM256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm-80.79 360.76h-29.84v-207.5h29.84zm-14.92-231.14a19.57 19.57.0 1119.57-19.57 19.64 19.64.0 01-19.57 19.57zM3e2 369h-81V161.26h80.6c76.73.0 110.44 54.83 110.44 103.85C410 318.39 368.38 369 3e2 369z"/></svg>
</span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://www.youtube.com/@robertunderwood97 target=_blank aria-label=Youtube rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78.0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
</span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://keybase.io/robertu94 target=_blank aria-label=Keybase rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M286.17 419a18 18 0 1018 18 18 18 0 00-18-18zm111.92-147.6c-9.5-14.62-39.37-52.45-87.26-73.71q-9.1-4.06-18.38-7.27A78.43 78.43.0 00244.57 86.29c-12.41-4.1-23.33-6-32.41-5.77-.6-2-1.89-11 9.4-35L198.66 32l-5.48 7.56c-8.69 12.06-16.92 23.55-24.34 34.89a51 51 0 00-8.29-1.25c-41.53-2.45-39-2.33-41.06-2.33-50.61.0-50.75 52.12-50.75 45.88l-2.36 36.68c-1.61 27 19.75 50.21 47.63 51.85l8.93.54a214 214 0 00-46.29 35.54C14 304.66 14 374 14 429.77v33.64l23.32-29.8a148.6 148.6.0 0014.56 37.56c5.78 10.13 14.87 9.45 19.64 7.33 4.21-1.87 10-6.92 3.75-20.11a178.29 178.29.0 01-15.76-53.13l46.82-59.83-24.66 74.11c58.23-42.4 157.38-61.76 236.25-38.59 34.2 10.05 67.45.69 84.74-23.84.72-1 1.2-2.16 1.85-3.22a156.09 156.09.0 012.8 28.43c0 23.3-3.69 52.93-14.88 81.64-2.52 6.46 1.76 14.5 8.6 15.74 7.42 1.57 15.33-3.1 18.37-11.15C429 443 434 414 434 382.32c0-38.58-13-77.46-35.91-110.92zM142.37 128.58l-15.7-.93-1.39 21.79 13.13.78a93 93 0 00.32 19.57l-22.38-1.34a12.28 12.28.0 01-11.76-12.79L107 119c1-12.17 13.87-11.27 13.26-11.32l29.11 1.73a144.35 144.35.0 00-7 19.17zm148.42 172.18a10.51 10.51.0 01-14.35-1.39l-9.68-11.49-34.42 27a8.09 8.09.0 01-11.13-1.08l-15.78-18.64a7.38 7.38.0 011.34-10.34l34.57-27.18-14.14-16.74-17.09 13.45a7.75 7.75.0 01-10.59-1s-3.72-4.42-3.8-4.53a7.38 7.38.0 011.37-10.34L214 225.19s-18.51-22-18.6-22.14a9.56 9.56.0 011.74-13.42 10.38 10.38.0 0114.3 1.37l81.09 96.32a9.58 9.58.0 01-1.74 13.44zM187.44 419a18 18 0 1018 18 18 18 0 00-18-18z"/></svg></span></a></div></div></div></div><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="group flex" href=/learning/intake/><span class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span><span class="ltr:hidden rtl:inline">&rarr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Learning to Learn: Intake</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2018-01-01 08:00:14 -0500 -0500">1 January 2018</time>
</span></span></a></span><span><a class="group flex text-right" href=/learning/cpp/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Learning to Learn: C++</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2018-01-12 19:00:14 -0500 -0500">12 January 2018</time>
</span></span><span class="ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[-2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&rarr;</span><span class="ltr:hidden rtl:inline">&larr;</span></span></a></span></div></div></footer></article></main><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12" id=to-top hidden=true><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Robert Underwood</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://github.com/jpanther/congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="flex flex-row items-center"></div></div></footer><div id=search-wrapper class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://robertu94.github.io/><div id=search-modal class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex flex-none items-center justify-between px-2"><form class="flex min-w-0 flex-auto items-center"><div class="flex h-8 w-8 items-center justify-center text-neutral-400"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto overflow-auto px-2"><ul id=search-results></ul></section></div></div></div></body></html>