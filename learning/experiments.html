<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>“Suggestions for the Design of Computational Experiments” | systems++</title>
<meta name=keywords content="Learning to Learn,HPC,Experiments">
<meta name=description content="So you want to do empirical computer science? Doing good science is difficult. It requires discipline and attention to detail. However there are strategies that can help you focus on answering the questions you can attempt to answer. First you should ask, “is this a scientific question?” Not all questions are scientific questions. Questions about aesthetics, values, ethics are not science questions. “Is A better than B?” is not a scientific question, it’s a question of values.">
<meta name=author content="Robert Underwood">
<link rel=canonical href=http://robertu94.github.io/learning/experiments.html>
<meta name=google-site-verification content="G-9KQE44SX6K">
<link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.baa4f2053c75d0009e9309aae8f8a8959f5e0372e88f80cdf2951a9533d71ce2.js integrity="sha256-uqTyBTx10ACekwmq6PiolZ9eA3Loj4DN8pUalTPXHOI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=http://robertu94.github.io/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=http://robertu94.github.io/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=http://robertu94.github.io/favicon-32x32.png>
<link rel=apple-touch-icon href=http://robertu94.github.io/apple-touch-icon.png>
<link rel=mask-icon href=http://robertu94.github.io/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9KQE44SX6K"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-9KQE44SX6K',{anonymize_ip:!1})}</script>
<meta property="og:title" content="“Suggestions for the Design of Computational Experiments”">
<meta property="og:description" content="So you want to do empirical computer science? Doing good science is difficult. It requires discipline and attention to detail. However there are strategies that can help you focus on answering the questions you can attempt to answer. First you should ask, “is this a scientific question?” Not all questions are scientific questions. Questions about aesthetics, values, ethics are not science questions. “Is A better than B?” is not a scientific question, it’s a question of values.">
<meta property="og:type" content="article">
<meta property="og:url" content="http://robertu94.github.io/learning/experiments.html"><meta property="article:section" content="learning">
<meta property="article:published_time" content="2022-10-18T08:00:00-05:00">
<meta property="article:modified_time" content="2022-10-18T08:00:00-05:00"><meta property="og:site_name" content="Systems++">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="“Suggestions for the Design of Computational Experiments”">
<meta name=twitter:description content="So you want to do empirical computer science? Doing good science is difficult. It requires discipline and attention to detail. However there are strategies that can help you focus on answering the questions you can attempt to answer. First you should ask, “is this a scientific question?” Not all questions are scientific questions. Questions about aesthetics, values, ethics are not science questions. “Is A better than B?” is not a scientific question, it’s a question of values.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"“Suggestions for the Design of Computational Experiments”","item":"http://robertu94.github.io/learning/experiments.html"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"“Suggestions for the Design of Computational Experiments”","name":"“Suggestions for the Design of Computational Experiments”","description":"So you want to do empirical computer science? Doing good science is difficult. It requires discipline and attention to detail. However there are strategies that can help you focus on answering the questions you can attempt to answer. First you should ask, “is this a scientific question?” Not all questions are scientific questions. Questions about aesthetics, values, ethics are not science questions. “Is A better than B?” is not a scientific question, it’s a question of values.","keywords":["Learning to Learn","HPC","Experiments"],"articleBody":"So you want to do empirical computer science? Doing good science is difficult. It requires discipline and attention to detail. However there are strategies that can help you focus on answering the questions you can attempt to answer. First you should ask, “is this a scientific question?” Not all questions are scientific questions. Questions about aesthetics, values, ethics are not science questions. “Is A better than B?” is not a scientific question, it’s a question of values. Questions of values require trade offs, and while important can’t be solved with the scientific method of stating assumptions, posing questions, designing experiments, collecting data, and interpreting results. “Can method A achieve more flops than method B in a given specific context?” Is more of a scientific question.\nAnother of the most important questions to ask is, “What are you trying to measure and what could it tell you?”. The latter part about what it could tell you is essential because it helps protect you from spurious conclusions that weren’t central when designing your system. Answering this pair of questions will often require you to clearly specify a model of your system and understand or at least have an educated guess about how your system works. Once you have answered that question (at least for now; you’ll often have to revise it with new data), my hope is that this document can give you some pointers on how to most efficiently and confidently answer your question.\nSystems Modeling The process of science begins with a hypothesis — a testable statement about the state or behavior of a system. Constructing a rigorous hypothesis requires a description of your system under test. The description is almost certain underdetermative of the total behavior of a system. It has been said that a model that is just as complex as the real system is just the real system. By design, models omit aspects of the systems they describe because these simplifications allow us to reason about the underlying behaviors we actually care about.\nThe process of creating these models is called systems modeling. While targeted, accurate, and concise systems modeling is challenging often relying on experience and expertise of the modeler or scientist constructing the model, there are a few principles that can be helpful:\nStart with a broad model that isn’t refined. Done appropriately you may be surprised about how accurate it is. You can always refine a broad model into a more accurate one by decomposing its parts into a more accurate model. Focus on the interfaces, inputs and outputs. These are the trickiest to get right, but also can give you the most leverage to tweak the behavior of your model.\nA rigorous model can often be phrased as a set of logical syllogisms. For example:\n Larger cache sizes have fewer evictions when executing code The more evictions there are, the slower the system will be on application 1 System A has a larger cache than System B Therefore System A will be faster than system B on Application 1  Readers familiar with caching know that is a pretty reductive model. You’ll probably need to account for factors like clock speed, algorithm, and eviction policy to get the accuracy you’re looking for on new applications of your model, but you could certainly start here and account for these differences later as you need them. As you make these changes, you’ll adjust the premises of your model to reflect the system and what you learn about it.\nStatistical Primer One of the most common mistakes I see in empirical computer science is to ignore the statistical principles when designing the experiments. Statistical principles can help you avoid drawing incorrect conclusions due to measurement or random error in your system.\nThere are a few key principles to keep in mind:\nConsider the 3Rs - randomness, replication, and reduction of noise. When designing experiments as much as is practicable you should repeat the experiments, reduce the effects of non-studied factors, and randomize what you can’t control.\nConsider your assumptions and consequences of violation. Every statistical method has assumptions and consequences of violation. The most common consequence is so called “liberal inference” which means that your experiment could give misleading results. Careful attention to assumptions can protect you from false conclusions.\nKnow the basis of Statistical Inference. Statistical Inference is the process of inferring the probability of the truth of some claim based on the results of some experiment. These methods can be either parametric and non-parametric. Parametric methods make assumptions about the distribution of the values of your observations. Non-parametric make fewer or weaker assumptions. One of the benefits of parametric methods is that they offer stronger evidence of a claim (I.e. require fewer replicas to draw a conclusion) than non parametric methods. The benefit of non parametric methods is that they make fewer assumptions and can be used validly in more cases.\nKnow some basics of Experimental Designs. There are several common designs including factorial, Latin squares/hyper cubes. When the experimental design space becomes large, tools such as orthogonal arrays can reduce the testing space. These methods can help provide structure that can help you avoid violating certain assumptions and keep the cost of your experiments down.\nChoose an appropriate Sample size. Statistical Inference offers a trade off between the rate of false positives and the sample size. Tests that require smaller sample sizes are called more powerful but often require more strict assumptions.\nThere is a lot more to statistics than what I can cover here. It’s worth reading a book or two on statistics methods. One such book is “A first course in design and analysis of experiments” by Gary W. Oehlert.\nSeparating Concerns There generally are three concerns when conducting a computer science experiment:\n Running the experiment Parsing the results into a machine readable form Taking the results and running analysis  I would advise writing a single script for each of these. That way you can easily run each part of the process independently if needed.\nRunning experiments When writing scripts and programs to run your experiments there are a number of tricks that can enable more productive code.\nWrite scalable code. Most experimental codes can be formulated as the execution of a “do_experiment” function that takes a configuration as an argument which can then be constructed using the Cartesian product of a set of factors.\nfrom itertools import product def do_experiment(args): # run experiment return ex_results Approaches = [1,2,3] Replicates = 5 Results = [] for _, approach in product(range(replicates), approaches): Results.append(do_experiment(approach)) Code like this can be easily parallelized and distributed using something like a MPI4Py MPICommExecutor (python) or libdistributed work queue (c++). The C++ equivalent of product is std::views::cartesian_product or range-v3’s cartesian_product.\nKnow how to accurately measure things. Measuring fine grained timing can be a nuanced process. First, for sub-millisecond timings, the clock resolution can matter. Second, not all clocks are monotonic. Third, some clocks have high measurement overhead for the first three cases in c++ you generally want the std::chrono::steady_clock in Python the equivalent is time.perf_counter_ns . Fourth, your compiler may optimize away your benchmark unless you force it to keep it (Google Benchmark has a function called benchmark::DoNotOptimize) which generally does the right thing). Fifth, other processes may interfere with your measurement (especially print statements) so avoid doing expensive operations during your benchmark timings. Lastly not all clocks can measure all processes, for example the C++ clock functions cannot measure the timing of Cuda operations accurately because they cannot observe device state.\nKnow your scheduler A common mistake that I see new students make is to run all jobs interactively, and not make use of the scheduler to run their job. Additionally your scheduler can do many things for you such as email you when your job finishes, start one job after a previous job finishes, handle process pinning and resource allocation and more. Its worth reading what it is capable of.\nKnow a higher level programming language. Systems programming languages like C,C++ and Rust are remarkably powerful and useful tools for writing benchmarks and experiments. However not all parts of the experimental process need this level of performance. For example plotting and data scraping tasks often aren’t as well suited to lower level languages and require large volumes of code for simple tasks. Likewise only recently has C++ gained higher level abstraction for Cartesian iteration. Prefer a higher level language for these tasks when possible.\nUnderstand sources of variability and control them if possible. Computer systems have many sources of variability. This could be clock variability, interference variability, seed variability, or process variability. Many, but not all of these sources of variability can be mitigated with appropriate steps. Attempt to control this variability if it is practical to do so.\nOutput as much context as possible. Especially with long running tasks having appropriate debugging information is key to reduce the number of run, interpret, modify cycles to a minimum. In doing so, remember what the system can record for you such as core dumps when the system crashes. Some context to specifically record include timestamps, task ids (if they are deterministic), complete error messages, error status, and progress indicators.\nKnow a distributed programming framework. For many problems running code on a single node isn’t enough. You want to be able to run experiments over several nodes collaboratively. While it is possible to do this with TCP/IP, it isn’t often the best way. In HPC the tool of choice is often MPI which provides both tools that are easy to start with and provides room to grow. However, other choices include RPC systems such as Mochi and GRPC.\nMake the testing environment reproducible (spack, docker, etc…). Reproducibility is a crisis in science; do not contribute to this crisis. Tools from industry like containers can make that much easier. Docker/Podman is my favorite, and is reasonably easy to use. Generally these tools boil down to writing a specialized script that reproduces your environment exactly which can then be shipped to users in the form of a compressed archive. Sometimes (especially when specialized hardware is involved) this is easier said than done. You might need a different version of software depending on your hardware platform. Spack is a powerful package manager that can help you solve some of these more complicated dependencies, but warrants its own post. Together these tools give you a powerful platform to run experiments easily on diverse machines. Tools like singularity let you run containers on HPC systems.\nPrefer parseable output, but sometimes you can’t. See the next section on writing parsable outputs. However, because many HPC libraries write to stdout/stderr, you can’t assume that you will have these to yourself. MPI implementations can be especially loud (for good reason) when they don’t believe that they are configured correctly.\nValidate on small cases first if possible. Waiting on the scheduler to run your job can be painful. If possible, have some small subset that you can verify works “correctly” before jumping to a supercomputer where your runtime environment becomes more complex and queuing times slow your ability to iterate on your experiments. Many supercomputers also charge for every execution and the costs can add up quickly.\nWrite the code to do partial writes, and resume-able in case the code crashes. There are few things more frustrating than for code to run for a few hours, crash (or timeout), and not have any results to show for it. It is often preferable to write results incrementally as your experiment is running than waiting until the end. This also often lets you use a pattern known as checkpoint restart where you resume execution at the state after your last failed/incomplete run. This makes it far easier to restart your job later to finish what’s left rather than start over from scratch. This is often as easy as partitioning the output into non overlapping regions or ids and writing the output. If this can’t be done a master process can be delegated to store the output\nWrite the code to handle error conditions as gracefully as possible. Likewise thinking about the error propagation boundaries for your code. In the pseudo code above placing a mandatory error propagation boundary just outside calls do_experiment will do what you want: isolate a fault from one experiment from another experiment allowing as many experiments to continue as possible without a crash in one experiment affecting other experiments. This can be tricky. Things like MPI have the default behavior of terminating the world on a signal. Other things like HDF5 with many blocking function calls might not catch that other threads of execution finished in a error state and will block indefinitely. This long tail of failures to tolerate can be constructed incrementally as you encounter them.\nAs an aside: sigsegv or its cousins sigfpe and sigbus are often implemented as catch-able signal but the mechanisms for recovering from it in standard C/C++ fully and correctly are limited or non-existent. Even if you think you can recover correctly from these signals don’t; you probably shouldn’t and should let the entire C runtime restart instead. What is easier and arguably better is to use another program (ie bash/python scripts) to handle this particular fault boundary.\nHere is an example that tries to implement as much of this as possible:\n#!/usr/bin/env python from mpi4py.futures import MPICommExecutor, as_completed from itertools import product from csv import DictWriter, DictReader from time import perf_counter_ns def do_experiment(args): starttime = perf_counter_ns() replicate, approach = args if replicate == 3: # example error raise RuntimeError(\"bad error happened here!\") # do the actual experiment here, then put results in a dict # including a starttime and endtime can really help you debug things ex_results = { \"result1\": replicate * 2, \"result2\": replicate, \"starttime\": starttime, \"endtime\": perf_counter_ns() } return ex_results FIELDS = [\"approach\", \"replicate\", \"starttime\", \"endtime\", \"result1\", \"result2\", \"err\"] approaches = [1, 2, 3] replicates = 5 futures = [] in_checkpoint = set() tasks = list(product(range(replicates), approaches)) fut_to_task = {} with MPICommExecutor() as pool: # only the root mpi rank enters this if-statement # the other processes will be workers if pool is not None: # check our results file to skip all results that are already successful try: with open(\"output_file.csv\") as checkpoint_file: reader = DictReader(checkpoint_file, FIELDS) for row in reader: if row['err'] == \"\": in_checkpoint.add((int(row['replicate']), int(row['approach']))) exists = True except FileNotFoundError: exists = False pass # start all of the tasks we care about for task in tasks: if task not in in_checkpoint: fut = pool.submit(do_experiment, task) futures.append(fut) fut_to_task[fut] = task # write results as we find them with open(\"output_file.csv\", \"a\" if exists else \"w\") as outfile: writer = DictWriter(outfile, FIELDS) if not exists: writer.writeheader() for fut in as_completed(futures): try: result = fut.result() task = fut_to_task[fut] print(\"task \", task, \"completed successfully\") result[\"err\"] = \"\" result[\"replicate\"] = task[0] result[\"approach\"] = task[1] writer.writerow(result) except Exception as ex: result = {} task = fut_to_task[fut] print(\"task \", task, \"failed\") result[\"err\"] = str(ex) result[\"replicate\"] = task[0] result[\"approach\"] = task[1] writer.writerow(result) Writing parsing code When parsing the results of experiments it is often helpful to do so in ways that are machine parse-able. While you almost certainly could write a domain specific language that often isn’t the best use of your time or resources. Sticking to a few well established formats can tremendously simplify the task ahead of you.\n CSV is ubiquitous and easy to generate. For this reason it is usually the first thing I reach for as long as the data isn’t hierarchical or non-scalar in nature. JSON is usually the next step that I reach for when I need simple arrays or basic hierarchies represented in my output. There are decent JSON parsing libraries in nearly every language which makes it easy to work with. Google’s protobuf is also not a bad option when JSON parsing speed is a limitation and you have a stable schema. While not as common in HPC it does a decent job of representing complex scalars and moderate hierarchies in ways that can be checked against a schema for validity. HDF5 as a structured, scalable data container. If you need to store large tensors (higher dimensional matrices) of data with hierarchical relationships, it is one of the few games in town. It also tends to have decent support in a variety of languages. SQLite can be another highly portable output format when your data is highly relational. It is also supported on nearly every platform under the sun. Binary files - writing a binary flat file is a possibility when the data format is relatively simple (ie a single large array), and nearly all languages support this. However it is seldom the best format because it doesn’t communicate some subtleties like endianness and and dimensionality that formats like HDF5 provide in addition to features like compression or attributes. regular expressions are a powerful tool of last resort for getting data out of your experiments. However needing a regular expression is often a suggestion that your output would benefit from greater structure and/or isolation. There are great websites that can help you rapidly prototype and validate your regular expressions for a variety of regular expression dialects.  When using tabular outputs like CSV use one row per experiment, one column per field. This makes it much easier to do joins and parsing of your experimental results to other tables of data much easier. If possible avoid literal new line characters or field delimitors in fields (especially error message fields) instead either 1 know how to escape them or replace them with characters without special interpretations.\nWhen using tabular data include a column for errors or execution irregularities. Experimental errors happen. Having a way built in to both filter in/out and summarize these kinds or errors can save you a lot of time trying to interpret your results and issues encountered during your experiments.\nParsing code often doesn’t benefit as much from parallelism so don’t worry about this upfront. Serial execution is a good enough place to start. An exception to this is where your data is a large tensor in which case parallel HDF5 is your friend for scalable IO performance.\nSince the previous example used csv and wrote to a dedicated file, we don’t even have to write the parsing code, we can just use pandas.read_csv\nWriting plotting/analysis code Choose a language which has mature tools for this. Unless you are doing sophisticated 3D graphics where libraries like VTK or OpenGL or Vulcan are required, you can accomplish a lot more a lot faster with libraries in Python (Seaborn/Matplotlib) or Julia (Makie/ Plots.jl). C++ is not the best tool for every job.\nSeparate plotting/analysis from parsing parsing the log files. Often one of these tasks will take much longer than you’d expect. By separating these tasks, you can work with the clean data more iteration and quickly drill in on a plot that does what you want.\nPrefer vector graphics for 2D plots. Vector graphics automatically scale to arbitrary resolution because they are described as a series of equations rather than a “map” of colors. In many plotting libraries this is as simple as choosing an eps or svg format output.\nA simple script that plots the runtime for each might look like this:\nimport pandas as pd import seaborn as sns df = pd.read_csv(\"output_file.csv\") df['runtime'] = df['endtime'] - df['starttime'] # understand what kinds of errors occured errs = df[df.err.notnull()] print(errs.err.value_counts()) # filter out results with errors success = df[df.err.isna()] # plot the timings sns.set(rc={\"figure.figsize\": (10, 7.5)}) sns.set_theme(context=\"talk\", style=\"whitegrid\") fig = sns.barplot(x=\"approach\", y=\"runtime\", data=success) fig.get_figure().savefig(\"runtime.eps\") Changelog  2022-10-18 – initial version  ","wordCount":"3266","inLanguage":"en","datePublished":"2022-10-18T08:00:00-05:00","dateModified":"2022-10-18T08:00:00-05:00","author":{"@type":"Person","name":"Robert Underwood"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://robertu94.github.io/learning/experiments.html"},"publisher":{"@type":"Organization","name":"systems++","logo":{"@type":"ImageObject","url":"http://robertu94.github.io/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=http://robertu94.github.io/ accesskey=h title="systems++ (Alt + H)">systems++</a>
<div class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</div>
</div>
<ul id=menu>
<li>
<a href=http://robertu94.github.io/about.html title="About Me">
<span>About Me</span>
</a>
</li>
<li>
<a href=http://robertu94.github.io/guides.html title=Guides>
<span>Guides</span>
</a>
</li>
<li>
<a href=http://robertu94.github.io/learning.html title="Learning To Learn">
<span>Learning To Learn</span>
</a>
</li>
<li>
<a href=http://robertu94.github.io/presentations.html title=Presentations>
<span>Presentations</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=http://robertu94.github.io/>Home</a></div>
<h1 class=post-title>
“Suggestions for the Design of Computational Experiments”
</h1>
<div class=post-meta><span title="2022-10-18 08:00:00 -0500 -0500">October 18, 2022</span>&nbsp;·&nbsp;16 min&nbsp;·&nbsp;3266 words&nbsp;·&nbsp;Robert Underwood
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><nav id=TableOfContents>
<ul>
<li><a href=#systems-modeling>Systems Modeling</a></li>
<li><a href=#statistical-primer>Statistical Primer</a></li>
<li><a href=#separating-concerns>Separating Concerns</a>
<ul>
<li><a href=#running-experiments>Running experiments</a></li>
<li><a href=#writing-parsing-code>Writing parsing code</a></li>
<li><a href=#writing-plottinganalysis-code>Writing plotting/analysis code</a></li>
</ul>
</li>
<li><a href=#changelog>Changelog</a></li>
</ul>
</nav>
</div>
</details>
</div>
<div class=post-content><p>So you want to do empirical computer science? Doing good science is difficult. It requires discipline and attention to detail. However there are strategies that can help you focus on answering the questions you can attempt to answer. First you should ask, “is this a scientific question?” Not all questions are scientific questions. Questions about aesthetics, values, ethics are not science questions. “Is A better than B?” is not a scientific question, it’s a question of values. Questions of values require trade offs, and while important can’t be solved with the scientific method of stating assumptions, posing questions, designing experiments, collecting data, and interpreting results. “Can method A achieve more flops than method B in a given specific context?” Is more of a scientific question.</p>
<p>Another of the most important questions to ask is, “What are you trying to measure and what could it tell you?”. The latter part about what it could tell you is essential because it helps protect you from spurious conclusions that weren’t central when designing your system. Answering this pair of questions will often require you to clearly specify a model of your system and understand or at least have an educated guess about how your system works. Once you have answered that question (at least for now; you’ll often have to revise it with new data), my hope is that this document can give you some pointers on how to most efficiently and confidently answer your question.</p>
<h1 id=systems-modeling>Systems Modeling<a hidden class=anchor aria-hidden=true href=#systems-modeling>#</a></h1>
<p>The process of science begins with a hypothesis — a testable statement about the state or behavior of a system. Constructing a rigorous hypothesis requires a description of your system under test. The description is almost certain underdetermative of the total behavior of a system. It has been said that a model that is just as complex as the real system is just the real system. By design, models omit aspects of the systems they describe because these simplifications allow us to reason about the underlying behaviors we actually care about.</p>
<p>The process of creating these models is called systems modeling. While targeted, accurate, and concise systems modeling is challenging often relying on experience and expertise of the modeler or scientist constructing the model, there are a few principles that can be helpful:</p>
<p>Start with a broad model that isn’t refined. Done appropriately you may be surprised about how accurate it is.
You can always refine a broad model into a more accurate one by decomposing its parts into a more accurate model.
Focus on the interfaces, inputs and outputs. These are the trickiest to get right, but also can give you the most leverage to tweak the behavior of your model.</p>
<p>A rigorous model can often be phrased as a set of logical syllogisms. For example:</p>
<ol>
<li>Larger cache sizes have fewer evictions when executing code</li>
<li>The more evictions there are, the slower the system will be on application 1</li>
<li>System A has a larger cache than System B</li>
<li>Therefore System A will be faster than system B on Application 1</li>
</ol>
<p>Readers familiar with caching know that is a pretty reductive model. You’ll probably need to account for factors like clock speed, algorithm, and eviction policy to get the accuracy you’re looking for on new applications of your model, but you could certainly start here and account for these differences later as you need them. As you make these changes, you’ll adjust the premises of your model to reflect the system and what you learn about it.</p>
<h1 id=statistical-primer>Statistical Primer<a hidden class=anchor aria-hidden=true href=#statistical-primer>#</a></h1>
<p>One of the most common mistakes I see in empirical computer science is to ignore the statistical principles when designing the experiments. Statistical principles can help you avoid drawing incorrect conclusions due to measurement or random error in your system.</p>
<p>There are a few key principles to keep in mind:</p>
<p><em>Consider the 3Rs</em> - randomness, replication, and reduction of noise. When designing experiments as much as is practicable you should repeat the experiments, reduce the effects of non-studied factors, and randomize what you can’t control.</p>
<p><em>Consider your assumptions and consequences of violation</em>. Every statistical method has assumptions and consequences of violation. The most common consequence is so called “liberal inference” which means that your experiment could give misleading results. Careful attention to assumptions can protect you from false conclusions.</p>
<p><em>Know the basis of Statistical Inference</em>. Statistical Inference is the process of inferring the probability of the truth of some claim based on the results of some experiment. These methods can be either parametric and non-parametric. Parametric methods make assumptions about the distribution of the values of your observations. Non-parametric make fewer or weaker assumptions. One of the benefits of parametric methods is that they offer stronger evidence of a claim (I.e. require fewer replicas to draw a conclusion) than non parametric methods. The benefit of non parametric methods is that they make fewer assumptions and can be used validly in more cases.</p>
<p><em>Know some basics of Experimental Designs</em>. There are several common designs including factorial, Latin squares/hyper cubes. When the experimental design space becomes large, tools such as orthogonal arrays can reduce the testing space. These methods can help provide structure that can help you avoid violating certain assumptions and keep the cost of your experiments down.</p>
<p><em>Choose an appropriate Sample size</em>. Statistical Inference offers a trade off between the rate of false positives and the sample size. Tests that require smaller sample sizes are called more powerful but often require more strict assumptions.</p>
<p>There is a lot more to statistics than what I can cover here. It’s worth reading a book or two on statistics methods. One such book is “A first course in design and analysis of experiments” by Gary W. Oehlert.</p>
<h1 id=separating-concerns>Separating Concerns<a hidden class=anchor aria-hidden=true href=#separating-concerns>#</a></h1>
<p>There generally are three concerns when conducting a computer science experiment:</p>
<ol>
<li>Running the experiment</li>
<li>Parsing the results into a machine readable form</li>
<li>Taking the results and running analysis</li>
</ol>
<p>I would advise writing a single script for each of these. That way you can easily run each part of the process independently if needed.</p>
<h2 id=running-experiments>Running experiments<a hidden class=anchor aria-hidden=true href=#running-experiments>#</a></h2>
<p>When writing scripts and programs to run your experiments there are a number of tricks that can enable more productive code.</p>
<p><em>Write scalable code</em>. Most experimental codes can be formulated as the execution of a “do_experiment” function that takes a configuration as an argument which can then be constructed using the Cartesian product of a set of factors.</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=kn>from</span> <span class=nn>itertools</span> <span class=kn>import</span> <span class=n>product</span>


<span class=k>def</span> <span class=nf>do_experiment</span><span class=p>(</span><span class=n>args</span><span class=p>):</span>
     <span class=c1># run experiment</span>
     <span class=k>return</span> <span class=n>ex_results</span>

<span class=n>Approaches</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>]</span>
<span class=n>Replicates</span> <span class=o>=</span> <span class=mi>5</span>
<span class=n>Results</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>_</span><span class=p>,</span> <span class=n>approach</span> <span class=ow>in</span> <span class=n>product</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>replicates</span><span class=p>),</span> <span class=n>approaches</span><span class=p>):</span>
    <span class=n>Results</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>do_experiment</span><span class=p>(</span><span class=n>approach</span><span class=p>))</span>
</code></pre></div><p>Code like this can be easily parallelized and distributed using something like a MPI4Py MPICommExecutor (python) or libdistributed work queue (c++). The C++ equivalent of product is <code>std::views::cartesian_product</code> or range-v3’s <code>cartesian_product</code>.</p>
<p><em>Know how to accurately measure things</em>. Measuring fine grained timing can be a nuanced process. First, for sub-millisecond timings, the clock resolution can matter. Second, not all clocks are monotonic. Third, some clocks have high measurement overhead for the first three cases in c++ you generally want the <code>std::chrono::steady_clock</code> in Python the equivalent is <code>time.perf_counter_ns</code> . Fourth, your compiler may optimize away your benchmark unless you force it to keep it (Google Benchmark has a function called <code>benchmark::DoNotOptimize</code>) which generally does the right thing). Fifth, other processes may interfere with your measurement (especially print statements) so avoid doing expensive operations during your benchmark timings. Lastly not all clocks can measure all processes, for example the C++ clock functions cannot measure the timing of Cuda operations accurately because they cannot observe device state.</p>
<p><em>Know your scheduler</em> A common mistake that I see new students make is to run all jobs interactively, and not make use of the scheduler to run their job. Additionally your scheduler can do many things for you such as email you when your job finishes, start one job after a previous job finishes, handle process pinning and resource allocation and more. Its worth reading what it is capable of.</p>
<p><em>Know a higher level programming language</em>. Systems programming languages like C,C++ and Rust are remarkably powerful and useful tools for writing benchmarks and experiments. However not all parts of the experimental process need this level of performance. For example plotting and data scraping tasks often aren’t as well suited to lower level languages and require large volumes of code for simple tasks. Likewise only recently has C++ gained higher level abstraction for Cartesian iteration. Prefer a higher level language for these tasks when possible.</p>
<p><em>Understand sources of variability and control them if possible</em>. Computer systems have many sources of variability. This could be clock variability, interference variability, seed variability, or process variability. Many, but not all of these sources of variability can be mitigated with appropriate steps. Attempt to control this variability if it is practical to do so.</p>
<p><em>Output as much context as possible</em>. Especially with long running tasks having appropriate debugging information is key to reduce the number of run, interpret, modify cycles to a minimum. In doing so, remember what the system can record for you such as core dumps when the system crashes. Some context to specifically record include timestamps, task ids (if they are deterministic), complete error messages, error status, and progress indicators.</p>
<p><em>Know a distributed programming framework</em>. For many problems running code on a single node isn’t enough. You want to be able to run experiments over several nodes collaboratively. While it is possible to do this with TCP/IP, it isn’t often the best way. In HPC the tool of choice is often MPI which provides both tools that are easy to start with and provides room to grow. However, other choices include RPC systems such as Mochi and GRPC.</p>
<p><em>Make the testing environment reproducible (spack, docker, etc…)</em>. Reproducibility is a crisis in science; do not contribute to this crisis. Tools from industry like containers can make that much easier. Docker/Podman is my favorite, and is reasonably easy to use. Generally these tools boil down to writing a specialized script that reproduces your environment exactly which can then be shipped to users in the form of a compressed archive. Sometimes (especially when specialized hardware is involved) this is easier said than done. You might need a different version of software depending on your hardware platform. Spack is a powerful package manager that can help you solve some of these more complicated dependencies, but warrants its own post. Together these tools give you a powerful platform to run experiments easily on diverse machines. Tools like singularity let you run containers on HPC systems.</p>
<p><em>Prefer parseable output, but sometimes you can’t</em>. See the next section on writing parsable outputs. However, because many HPC libraries write to stdout/stderr, you can’t assume that you will have these to yourself. MPI implementations can be especially loud (for good reason) when they don’t believe that they are configured correctly.</p>
<p><em>Validate on small cases first if possible</em>. Waiting on the scheduler to run your job can be painful. If possible, have some small subset that you can verify works “correctly” before jumping to a supercomputer where your runtime environment becomes more complex and queuing times slow your ability to iterate on your experiments. Many supercomputers also charge for every execution and the costs can add up quickly.</p>
<p><em>Write the code to do partial writes, and resume-able in case the code crashes</em>. There are few things more frustrating than for code to run for a few hours, crash (or timeout), and not have any results to show for it. It is often preferable to write results incrementally as your experiment is running than waiting until the end. This also often lets you use a pattern known as checkpoint restart where you resume execution at the state after your last failed/incomplete run. This makes it far easier to restart your job later to finish what’s left rather than start over from scratch. This is often as easy as partitioning the output into non overlapping regions or ids and writing the output. If this can’t be done a master process can be delegated to store the output</p>
<p><em>Write the code to handle error conditions as gracefully as possible</em>. Likewise thinking about the error propagation boundaries for your code. In the pseudo code above placing a mandatory error propagation boundary just outside calls do_experiment will do what you want: isolate a fault from one experiment from another experiment allowing as many experiments to continue as possible without a crash in one experiment affecting other experiments. This can be tricky. Things like MPI have the default behavior of terminating the world on a signal. Other things like HDF5 with many blocking function calls might not catch that other threads of execution finished in a error state and will block indefinitely. This long tail of failures to tolerate can be constructed incrementally as you encounter them.</p>
<p>As an aside: sigsegv or its cousins sigfpe and sigbus are often implemented as catch-able signal but the mechanisms for recovering from it in standard C/C++ fully and correctly are limited or non-existent. Even if you think you can recover correctly from these signals don’t; you probably shouldn’t and should let the entire C runtime restart instead. What is easier and arguably better is to use another program (ie bash/python scripts) to handle this particular fault boundary.</p>
<p>Here is an example that tries to implement as much of this as possible:</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=ch>#!/usr/bin/env python</span>
<span class=kn>from</span> <span class=nn>mpi4py.futures</span> <span class=kn>import</span> <span class=n>MPICommExecutor</span><span class=p>,</span> <span class=n>as_completed</span>
<span class=kn>from</span> <span class=nn>itertools</span> <span class=kn>import</span> <span class=n>product</span>
<span class=kn>from</span> <span class=nn>csv</span> <span class=kn>import</span> <span class=n>DictWriter</span><span class=p>,</span> <span class=n>DictReader</span>
<span class=kn>from</span> <span class=nn>time</span> <span class=kn>import</span> <span class=n>perf_counter_ns</span>


<span class=k>def</span> <span class=nf>do_experiment</span><span class=p>(</span><span class=n>args</span><span class=p>):</span>
    <span class=n>starttime</span> <span class=o>=</span> <span class=n>perf_counter_ns</span><span class=p>()</span>
    <span class=n>replicate</span><span class=p>,</span> <span class=n>approach</span> <span class=o>=</span> <span class=n>args</span>
    <span class=k>if</span> <span class=n>replicate</span> <span class=o>==</span> <span class=mi>3</span><span class=p>:</span>
        <span class=c1># example error</span>
        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s2>&#34;bad error happened here!&#34;</span><span class=p>)</span>

    <span class=c1># do the actual experiment here, then put results in a dict</span>
    <span class=c1># including a starttime and endtime can really help you debug things</span>
    <span class=n>ex_results</span> <span class=o>=</span> <span class=p>{</span>
        <span class=s2>&#34;result1&#34;</span><span class=p>:</span> <span class=n>replicate</span> <span class=o>*</span> <span class=mi>2</span><span class=p>,</span>
        <span class=s2>&#34;result2&#34;</span><span class=p>:</span> <span class=n>replicate</span><span class=p>,</span>
        <span class=s2>&#34;starttime&#34;</span><span class=p>:</span> <span class=n>starttime</span><span class=p>,</span>
        <span class=s2>&#34;endtime&#34;</span><span class=p>:</span> <span class=n>perf_counter_ns</span><span class=p>()</span>
    <span class=p>}</span>
    <span class=k>return</span> <span class=n>ex_results</span>


<span class=n>FIELDS</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;approach&#34;</span><span class=p>,</span> <span class=s2>&#34;replicate&#34;</span><span class=p>,</span> <span class=s2>&#34;starttime&#34;</span><span class=p>,</span> <span class=s2>&#34;endtime&#34;</span><span class=p>,</span> <span class=s2>&#34;result1&#34;</span><span class=p>,</span> <span class=s2>&#34;result2&#34;</span><span class=p>,</span> <span class=s2>&#34;err&#34;</span><span class=p>]</span>
<span class=n>approaches</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>]</span>
<span class=n>replicates</span> <span class=o>=</span> <span class=mi>5</span>
<span class=n>futures</span> <span class=o>=</span> <span class=p>[]</span>
<span class=n>in_checkpoint</span> <span class=o>=</span> <span class=nb>set</span><span class=p>()</span>
<span class=n>tasks</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>product</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>replicates</span><span class=p>),</span> <span class=n>approaches</span><span class=p>))</span>
<span class=n>fut_to_task</span> <span class=o>=</span> <span class=p>{}</span>

<span class=k>with</span> <span class=n>MPICommExecutor</span><span class=p>()</span> <span class=k>as</span> <span class=n>pool</span><span class=p>:</span>
    <span class=c1># only the root mpi rank enters this if-statement</span>
    <span class=c1># the other processes will be workers</span>
    <span class=k>if</span> <span class=n>pool</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
        <span class=c1># check our results file to skip all results that are already successful</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&#34;output_file.csv&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>checkpoint_file</span><span class=p>:</span>
                <span class=n>reader</span> <span class=o>=</span> <span class=n>DictReader</span><span class=p>(</span><span class=n>checkpoint_file</span><span class=p>,</span> <span class=n>FIELDS</span><span class=p>)</span>
                <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>reader</span><span class=p>:</span>
                    <span class=k>if</span> <span class=n>row</span><span class=p>[</span><span class=s1>&#39;err&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s2>&#34;&#34;</span><span class=p>:</span>
                        <span class=n>in_checkpoint</span><span class=o>.</span><span class=n>add</span><span class=p>((</span><span class=nb>int</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s1>&#39;replicate&#39;</span><span class=p>]),</span> <span class=nb>int</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s1>&#39;approach&#39;</span><span class=p>])))</span>
            <span class=n>exists</span> <span class=o>=</span> <span class=kc>True</span>
        <span class=k>except</span> <span class=ne>FileNotFoundError</span><span class=p>:</span>
            <span class=n>exists</span> <span class=o>=</span> <span class=kc>False</span>
            <span class=k>pass</span>

        <span class=c1># start all of the tasks we care about</span>
        <span class=k>for</span> <span class=n>task</span> <span class=ow>in</span> <span class=n>tasks</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>task</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>in_checkpoint</span><span class=p>:</span>
                <span class=n>fut</span> <span class=o>=</span> <span class=n>pool</span><span class=o>.</span><span class=n>submit</span><span class=p>(</span><span class=n>do_experiment</span><span class=p>,</span> <span class=n>task</span><span class=p>)</span>
                <span class=n>futures</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>fut</span><span class=p>)</span>
                <span class=n>fut_to_task</span><span class=p>[</span><span class=n>fut</span><span class=p>]</span> <span class=o>=</span> <span class=n>task</span>

        <span class=c1># write results as we find them</span>
        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&#34;output_file.csv&#34;</span><span class=p>,</span> <span class=s2>&#34;a&#34;</span> <span class=k>if</span> <span class=n>exists</span> <span class=k>else</span> <span class=s2>&#34;w&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>outfile</span><span class=p>:</span>
            <span class=n>writer</span> <span class=o>=</span> <span class=n>DictWriter</span><span class=p>(</span><span class=n>outfile</span><span class=p>,</span> <span class=n>FIELDS</span><span class=p>)</span>
            <span class=k>if</span> <span class=ow>not</span> <span class=n>exists</span><span class=p>:</span>
                <span class=n>writer</span><span class=o>.</span><span class=n>writeheader</span><span class=p>()</span>
            <span class=k>for</span> <span class=n>fut</span> <span class=ow>in</span> <span class=n>as_completed</span><span class=p>(</span><span class=n>futures</span><span class=p>):</span>
                <span class=k>try</span><span class=p>:</span>
                    <span class=n>result</span> <span class=o>=</span> <span class=n>fut</span><span class=o>.</span><span class=n>result</span><span class=p>()</span>
                    <span class=n>task</span> <span class=o>=</span> <span class=n>fut_to_task</span><span class=p>[</span><span class=n>fut</span><span class=p>]</span>
                    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;task &#34;</span><span class=p>,</span> <span class=n>task</span><span class=p>,</span> <span class=s2>&#34;completed successfully&#34;</span><span class=p>)</span>
                    <span class=n>result</span><span class=p>[</span><span class=s2>&#34;err&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
                    <span class=n>result</span><span class=p>[</span><span class=s2>&#34;replicate&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>task</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
                    <span class=n>result</span><span class=p>[</span><span class=s2>&#34;approach&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>task</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
                    <span class=n>writer</span><span class=o>.</span><span class=n>writerow</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
                <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>ex</span><span class=p>:</span>
                    <span class=n>result</span> <span class=o>=</span> <span class=p>{}</span>
                    <span class=n>task</span> <span class=o>=</span> <span class=n>fut_to_task</span><span class=p>[</span><span class=n>fut</span><span class=p>]</span>
                    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;task &#34;</span><span class=p>,</span> <span class=n>task</span><span class=p>,</span> <span class=s2>&#34;failed&#34;</span><span class=p>)</span>
                    <span class=n>result</span><span class=p>[</span><span class=s2>&#34;err&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>ex</span><span class=p>)</span>
                    <span class=n>result</span><span class=p>[</span><span class=s2>&#34;replicate&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>task</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
                    <span class=n>result</span><span class=p>[</span><span class=s2>&#34;approach&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>task</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
                    <span class=n>writer</span><span class=o>.</span><span class=n>writerow</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</code></pre></div><h2 id=writing-parsing-code>Writing parsing code<a hidden class=anchor aria-hidden=true href=#writing-parsing-code>#</a></h2>
<p><em>When parsing the results of experiments it is often helpful to do so in ways that are machine parse-able</em>. While you almost certainly could write a domain specific language that often isn’t the best use of your time or resources. Sticking to a few well established formats can tremendously simplify the task ahead of you.</p>
<ul>
<li>CSV is ubiquitous and easy to generate. For this reason it is usually the first thing I reach for as long as the data isn’t hierarchical or non-scalar in nature.</li>
<li>JSON is usually the next step that I reach for when I need simple arrays or basic hierarchies represented in my output. There are decent JSON parsing libraries in nearly every language which makes it easy to work with.</li>
<li>Google’s protobuf is also not a bad option when JSON parsing speed is a limitation and you have a stable schema. While not as common in HPC it does a decent job of representing complex scalars and moderate hierarchies in ways that can be checked against a schema for validity.</li>
<li>HDF5 as a structured, scalable data container. If you need to store large tensors (higher dimensional matrices) of data with hierarchical relationships, it is one of the few games in town. It also tends to have decent support in a variety of languages.</li>
<li>SQLite can be another highly portable output format when your data is highly relational. It is also supported on nearly every platform under the sun.</li>
<li>Binary files - writing a binary flat file is a possibility when the data format is relatively simple (ie a single large array), and nearly all languages support this. However it is seldom the best format because it doesn’t communicate some subtleties like endianness and and dimensionality that formats like HDF5 provide in addition to features like compression or attributes.</li>
<li>regular expressions are a powerful tool of last resort for getting data out of your experiments. However needing a regular expression is often a suggestion that your output would benefit from greater structure and/or isolation. There are great websites that can help you rapidly prototype and validate your regular expressions for a variety of regular expression dialects.</li>
</ul>
<p><em>When using tabular outputs like CSV use one row per experiment, one column per field</em>. This makes it much easier to do joins and parsing of your experimental results to other tables of data much easier. If possible avoid literal new line characters or field delimitors in fields (especially error message fields) instead either 1 know how to escape them or replace them with characters without special interpretations.</p>
<p><em>When using tabular data include a column for errors or execution irregularities</em>. Experimental errors happen. Having a way built in to both filter in/out and summarize these kinds or errors can save you a lot of time trying to interpret your results and issues encountered during your experiments.</p>
<p><em>Parsing code often doesn’t benefit as much from parallelism so don’t worry about this upfront</em>. Serial execution is a good enough place to start. An exception to this is where your data is a large tensor in which case parallel HDF5 is your friend for scalable IO performance.</p>
<p>Since the previous example used csv and wrote to a dedicated file, we don&rsquo;t even have to write the parsing code, we can just use <code>pandas.read_csv</code></p>
<h2 id=writing-plottinganalysis-code>Writing plotting/analysis code<a hidden class=anchor aria-hidden=true href=#writing-plottinganalysis-code>#</a></h2>
<p><em>Choose a language which has mature tools for this.</em> Unless you are doing sophisticated 3D graphics where libraries like VTK or OpenGL or Vulcan are required, you can accomplish a lot more a lot faster with libraries in Python (Seaborn/Matplotlib) or Julia (Makie/ Plots.jl). C++ is not the best tool for every job.</p>
<p><em>Separate plotting/analysis from parsing parsing the log files</em>. Often one of these tasks will take much longer than you’d expect. By separating these tasks, you can work with the clean data more iteration and quickly drill in on a plot that does what you want.</p>
<p><em>Prefer vector graphics for 2D plots</em>. Vector graphics automatically scale to arbitrary resolution because they are described as a series of equations rather than a “map” of colors. In many plotting libraries this is as simple as choosing an eps or svg format output.</p>
<p>A simple script that plots the runtime for each might look like this:</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span>
<span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&#34;output_file.csv&#34;</span><span class=p>)</span>
<span class=n>df</span><span class=p>[</span><span class=s1>&#39;runtime&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;endtime&#39;</span><span class=p>]</span> <span class=o>-</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;starttime&#39;</span><span class=p>]</span>


<span class=c1># understand what kinds of errors occured</span>
<span class=n>errs</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>df</span><span class=o>.</span><span class=n>err</span><span class=o>.</span><span class=n>notnull</span><span class=p>()]</span>
<span class=nb>print</span><span class=p>(</span><span class=n>errs</span><span class=o>.</span><span class=n>err</span><span class=o>.</span><span class=n>value_counts</span><span class=p>())</span>

<span class=c1># filter out results with errors</span>
<span class=n>success</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>df</span><span class=o>.</span><span class=n>err</span><span class=o>.</span><span class=n>isna</span><span class=p>()]</span>

<span class=c1># plot the timings</span>
<span class=n>sns</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>rc</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;figure.figsize&#34;</span><span class=p>:</span> <span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mf>7.5</span><span class=p>)})</span>
<span class=n>sns</span><span class=o>.</span><span class=n>set_theme</span><span class=p>(</span><span class=n>context</span><span class=o>=</span><span class=s2>&#34;talk&#34;</span><span class=p>,</span> <span class=n>style</span><span class=o>=</span><span class=s2>&#34;whitegrid&#34;</span><span class=p>)</span>
<span class=n>fig</span> <span class=o>=</span> <span class=n>sns</span><span class=o>.</span><span class=n>barplot</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=s2>&#34;approach&#34;</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=s2>&#34;runtime&#34;</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=n>success</span><span class=p>)</span>
<span class=n>fig</span><span class=o>.</span><span class=n>get_figure</span><span class=p>()</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s2>&#34;runtime.eps&#34;</span><span class=p>)</span>
</code></pre></div><h1 id=changelog>Changelog<a hidden class=anchor aria-hidden=true href=#changelog>#</a></h1>
<ul>
<li>2022-10-18 &ndash; initial version</li>
</ul>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=http://robertu94.github.io/tags/learning-to-learn.html>Learning to Learn</a></li>
<li><a href=http://robertu94.github.io/tags/hpc.html>HPC</a></li>
<li><a href=http://robertu94.github.io/tags/experiments.html>Experiments</a></li>
</ul>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=http://robertu94.github.io/>systems++</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>